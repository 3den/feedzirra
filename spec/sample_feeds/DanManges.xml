<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="http://feeds.feedburner.com/~d/styles/rss2full.xsl" type="text/xsl" media="screen"?><?xml-stylesheet href="http://feeds.feedburner.com/~d/styles/itemcontent.css" type="text/css" media="screen"?><rss version="2.0">
  <channel>
    <title>Dan Manges</title>
    <link>http://www.dcmanges.com/blog</link>
    <pubDate>Thu, 04 Dec 2008 05:21:00 GMT</pubDate>
    <description>Dan Manges - Blog</description>
    <atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" href="http://feeds.feedburner.com/dcmanges" type="application/rss+xml" /><item>
      <title>Action Dependent Validations and Why :on =&gt; :update is Bad</title>
      <link>http://www.dcmanges.com/blog/action-dependent-validations-and-why-on-update-is-bad</link>
      <description>&lt;p&gt;
  ActiveRecord validations typically apply all the time. For example, a &lt;tt&gt;User&lt;/tt&gt; object may be required to always have an &lt;tt&gt;email_address.&lt;/tt&gt;
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class User &lt; ActiveRecord::Base
  validates_presence_of :email_address
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  But validations can also be set depending on the action being taken on the object. For example, let's say when a &lt;tt&gt;User&lt;/tt&gt; is first created it &lt;strong&gt;does not&lt;/strong&gt; need to have a &lt;tt&gt;password&lt;/tt&gt;. Before the user can set his or her password, he needs to click an activation link in an e-mail. We can tell ActiveRecord to only require a password when updating the User.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class User &lt; ActiveRecord::Base
  validates_presence_of :password, :on =&gt; :update
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  But &lt;tt&gt;:on =&amp;gt; :update&lt;/tt&gt; is almost never what you want.
&lt;/p&gt;

&lt;h2&gt;The Smell&lt;/h2&gt;

&lt;p&gt;
  Let's take a quick look at the validation behavior of this workflow. We initially create a &lt;tt&gt;User&lt;/tt&gt; with only an e-mail address.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
  User.create! :email_address =&gt; "daniel.manges@gmail.com"
  #=&gt; #&lt;User id: 1, email_address: "daniel.manges@gmail.com", password: nil&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  So far, so good. Now what if something comes up where we want to verify that all the records in the database are valid? We'll find the user and make sure &lt;tt&gt;valid?&lt;/tt&gt; returns true.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
user = User.find(1)
user.valid?
#=&gt; false

user.errors.full_messages
#=&gt; ["Password can't be blank"]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  The record is invalid. But is it really? No. Users don't have to have passwords until activating. I think for any record in the database, you should be able to load the object, call &lt;tt&gt;valid?&lt;/tt&gt;, and get true. But this isn't just a theoretical issue, running validations &lt;tt&gt;:on =&amp;gt; :update&lt;/tt&gt; usually causes actual problems.
&lt;/p&gt;

&lt;h2&gt;The Intention of Validating on Update&lt;/h2&gt;

&lt;p&gt;
  We spend a lot of time as software developers trying to determine the intention of other developers. If code is fairly clean, we can easily tell what it does. But determining if the some of the behavior is intended or incidental is more difficult. Consider this code:
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class User &lt; ActiveRecord::Base
  validates_presence_of :password, :on =&gt; :update
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  I translate this code into: the &lt;strong&gt;very first time&lt;/strong&gt; a &lt;tt&gt;User&lt;/tt&gt; is updated after being created it must have a password.
&lt;/p&gt;

&lt;p&gt;
  That's a really strong constraint. What if I want to update the user another way without setting a password? If the user is activating his account, I want him to set his password. But an admin should be allowed to change some attributes on the user without setting the password. Because of the constraint imposed by this validation, what happens a lot of time is this:
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
user.some_flag = true
user.save(false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  If you're not familiar with &lt;tt&gt;save(false)&lt;/tt&gt;, it saves the record without running validations. Because the validations won't allow the user to be updated without setting a password, it's easy to resort to doing this. But it's dangerous - skipping validations can end up being a nightmare. You can't add a new validation and be sure that it will never be violated - you have to look for all occurrences of &lt;tt&gt;save(false)&lt;/tt&gt; to make sure none of them are circumventing.
&lt;/p&gt;

&lt;h2&gt;The Solution&lt;/h2&gt;

&lt;p&gt;
  Let's go back to the requirement. &lt;i&gt;When a user activates his account, he must set a password.&lt;/i&gt; To implement this, we need a way to have a validation run only on activation. Here's one way to do this:
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class User &lt; ActiveRecord::Base
  
  def save_on_activation
    return false unless valid_for_activation?
    save!
  end
  
  def valid_for_activation?
    valid? # run all validations
    errors.add(:password, "cannot be blank") if password.blank?
    errors.empty?
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  Having &lt;tt&gt;save_on_activation&lt;/tt&gt; and &lt;tt&gt;valid_for_activation?&lt;/tt&gt; methods makes it easy to control when the validations apply. If you like the declarative nature of the ActiveRecord validations, you could set some state and then use the &lt;tt&gt;:if&lt;/tt&gt; option like this:
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class User &lt; ActiveRecord::Base
  validates_presence_of :password, :if =&gt; :activating?
  
  def save_on_activation
    @activating = true
    save
  ensure
    @activating = false
  end
  
  def activating?
    @activating
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  With this implementation, setting the &lt;tt&gt;@activating&lt;/tt&gt; instance variable causes the validation to be run.
&lt;/p&gt;

&lt;h2&gt;Validation Groups&lt;/h2&gt;

&lt;p&gt;
  If you need a lot of separate validation groups like this, managing all the validations can become tricky. For example, this &lt;tt&gt;save_on_activation&lt;/tt&gt; method applies the validation on the appropriate action, but what about when a user is updating his profile, which includes a password edit field? We need to make sure he can't set a blank password. So we want this validation to run on both activation and edit.
&lt;/p&gt;

&lt;p&gt;
  &lt;a href="http://validatable.rubyforge.org"&gt;Validatable&lt;/a&gt; is a validation framework that allows grouping validations in a declarative style. I haven't used it with Rails 2.x, but with Rails 1.2 you could include Validatable in an ActiveRecord class and it would just work. Anyway, with validatable the code would look like this:
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class User &lt; ActiveRecord::Base
  include Validatable
  
  validates_presence_of :password, :groups =&gt; [:activation, :edit]
  
  def save_on_activation
    return false unless valid_for_activation?
    save  
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;
  For some requirements &lt;tt&gt;:on =&amp;gt; :update&lt;/tt&gt; seems to be the answer. One is the example from this blog post, where an attribute isn't required when something is created, but it is required when the record is updated later. Another is legacy data. It's typical for legacy data not to comply with a validation, but new records and updated legacy records should adhere to it. In either of these scenarios I think it's better to make custom save and valid methods than it is to use &lt;tt&gt;:on =&amp;gt; :update&lt;/tt&gt;.
&lt;/p&gt;

&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/action-dependent-validations-and-why-on-update-is-bad"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Thu, 04 Dec 2008 05:16:06 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/action-dependent-validations-and-why-on-update-is-bad</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Rails Application Visualization</title>
      <link>http://www.dcmanges.com/blog/rails-application-visualization-with-munin</link>
      <description>&lt;p&gt;
  Before we went live with the new Rails site at &lt;a href="http://www.carepages.com"&gt;CarePages&lt;/a&gt;, we decided to use Munin for monitoring. We needed to write a few custom plugins to visualize application health. Fortunately, Munin plugins are really easy to write - I'll provide the source for a couple of them. We wrote plugins for Passenger process status, Passenger memory stats, Rails response time, Rails hits, the ARMailer queue, and the BJ queue. Munin also comes with default plugins for things like CPU and memory usage that are good to use for correlation.
&lt;/p&gt;

&lt;h2&gt;Passenger Status&lt;/h2&gt;

&lt;p&gt;
  Passenger has a &lt;tt&gt;passenger-status&lt;/tt&gt; command that will output the status of all the Rails (or Rack) processes. It will provide the maximum number of processes that can be spawned, how many processing are currently running, and how many are in use. The output looks like this:
&lt;/p&gt;

&lt;pre&gt;
$ sudo passenger-status
----------- General information -----------
max      = 16
count    = 4
active   = 2
inactive = 3

----------- Applications -----------
/redacted/releases/20081024053350: 
  PID: 18984     Sessions: 0
  PID: 18980     Sessions: 0
  PID: 20126     Sessions: 1
  PID: 15735     Sessions: 1
&lt;/pre&gt;

&lt;p&gt;
  And here's the Munin graph. Parsing the output of the &lt;tt&gt;passenger-status&lt;/tt&gt; command was simple, and provided good visibility into the application health. Here's the &lt;a href="http://gist.github.com/20319"&gt;source for the passenger-status munin plugin&lt;/a&gt;.
&lt;/p&gt;

&lt;img src="http://www.dcmanges.com/images/posts/passenger_status.png"&gt;

&lt;h2&gt;Passenger Memory Stats&lt;/h2&gt;

&lt;p&gt;
  Passenger also provides memory stats via &lt;tt&gt;passenger-memory-stats&lt;/tt&gt;. It will show the amount of memory being used per process. Here's what it looks like in the form of a Munin graph. You can see that as processes go idle when there's low traffic over night, Passenger kills them, freeing up memory. You can also see the application slowly leaking memory during the day.
&lt;/p&gt;

&lt;img src="http://www.dcmanges.com/images/posts/passenger_memory_stats.png"&gt;

&lt;h2&gt;Rails Hits&lt;/h2&gt;

&lt;p&gt;
  We wanted to be able to correlate utilization with actual traffic, so we also made a plugin to graph requests that hit Rails. We set up a custom log to make this easier, but in the end we had a plugin that would chart how many requests were hitting Rails every 5 minutes per app server.
&lt;/p&gt;

&lt;img src="http://www.dcmanges.com/images/posts/rails_hits.png"&gt;

&lt;h2&gt;Rails Response Time&lt;/h2&gt;

&lt;p&gt;
  And of course, we wanted to be able to see the app performance using mean and median response times. We logged Rails' X-Runtime header in our custom log, and we used that to produce yet another Munin graph. I'll blog about the details of that custom log later - we found several good uses for it.
&lt;/p&gt;

&lt;img src="http://www.dcmanges.com/images/posts/rails_response_time.png"&gt;

&lt;h2&gt;CPU&lt;/h2&gt;

&lt;p&gt;
  Munin comes with some default plugins that are good to correlate with the application-specific plugins that we wrote. For example, here's the CPU usage graph.
&lt;/p&gt;

&lt;img src="http://www.dcmanges.com/images/posts/cpu.png"&gt;

&lt;h2&gt;MySQL Queries&lt;/h2&gt;

&lt;p&gt;
  Munin also has bundled plugins for MySQL, making it easy to keep an eye on queries / second and slow queries.
&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.dcmanges.com/images/posts/mysql_queries.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.dcmanges.com/images/posts/mysql_slowqueries.png"&gt;&lt;/p&gt;

&lt;h2&gt;Background Queues&lt;/h2&gt;

&lt;p&gt;
  Finally, it was also easy to write plugins to keep an eye on background queues. Here's one that watches the AR Mailer queue.
&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.dcmanges.com/images/posts/ar_mailer_queue.png"&gt;&lt;/p&gt;

&lt;p&gt;
  And another that watches the BJ queue &lt;a href="http://gist.github.com/20321"&gt;(source)&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.dcmanges.com/images/posts/bj_queue.png"&gt;&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/rails-application-visualization-with-munin"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Tue, 28 Oct 2008 07:50:55 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/rails-application-visualization-with-munin</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Increasing Code Coverage May Be Harmful</title>
      <link>http://www.dcmanges.com/blog/increasing-code-coverage-may-be-harmful</link>
      <description>&lt;p&gt;
  I should start by clarifying: I'm referring to increasing code coverage by running a code coverage tool, looking for untested code, and writing tests for it. Here's an example.
&lt;/p&gt;

&lt;p&gt;
  Let's say you run your test coverage report and you find the following method is not tested.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class BankAccount
  def masked_number
    ("*" * 8) + number.to_s[-4, 4]
  end  
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  It's easy to see what this method does. I can get 100% coverage in a few seconds.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
describe "masked_number" do
  it "returns 8 asterisks followed by the
        last 4 characters of the account number" do
    account = BankAccount.new :number =&gt; 123456781234
    account.masked_number.should == "********1234"
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  Is the method tested? Yes. Is it tested well? No. What is it supposed to return if there is no account number? What if the account number is longer than 12 digits - should it still return 8 asterisks, or should it return more? Because &lt;tt&gt;masked_number&lt;/tt&gt; didn't have any tests, you have no idea if the author of the method considered these scenarios or not.
&lt;/p&gt;

&lt;p&gt;
  So let's say we assume that the original author of this method considered these possibilities and did the right thing. So we add a few more tests.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
describe "masked_number" do
  it "returns 8 asterisks if the account number is blank" do
    account = BankAccount.new :number =&gt; nil
    account.masked_number.should == "********"
  end

  it "returns 8 asterisks followed by the
        last 4 characters of the number for a
        14 digit account number" do
    account = BankAccount.new :number =&gt; 12345678901234
    account.masked_number.should == "********1234"
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  We now have 3 tests for this method, covering a few possible input values. Awesome. Maybe...
&lt;/p&gt;

&lt;p&gt;
  Now let's say a developer picks up a bug ticket from QA: "For an account number of length X, the account mask should show X - 4 asterisks and the last 4 digits of the account number. Right now it always shows 8 asterisks. For example, a 14 digit account number should have 10 asterisks."
&lt;/p&gt;

&lt;p&gt;
  So the developer decides to do TDD and write a test, but he or she notices the test that's already there. Now the quick thing to do would be to assume that the QA ticket is right and update the existing test. But that's not the responsible thing to do. If a test is there, indicating that a 14 digit account number should have 8 asterisks, somebody must have desired that behavior. Before changing the test and the code, the developer should find out who wrote the test. Does somebody else think it should be 8 asterisks? Does one part of the application always want 8, while another wants 10?
&lt;/p&gt;

&lt;p&gt;
  When faced with untested code, there are 3 approaches you can take, and all of them have drawbacks.
&lt;/p&gt;

&lt;p&gt;
  &lt;strong&gt;(1) Thoroughly test the method.&lt;/strong&gt;&lt;br /&gt;
  &lt;strong&gt;Advantage:&lt;/strong&gt; the method is now well tested.&lt;br /&gt;
  &lt;strong&gt;Disadvantage:&lt;/strong&gt; it may lead future developers astray by making something coincidental seem intentional.
&lt;/p&gt;

&lt;p&gt;
  &lt;strong&gt;(2) Do the minimal amount of testing to cover the method.&lt;/strong&gt;&lt;br /&gt;
  &lt;strong&gt;Advantage:&lt;/strong&gt; the method has some basic tests for it.&lt;br /&gt;
  &lt;strong&gt;Disadvantage:&lt;/strong&gt; you're focused on the wrong goal. You should strive for well tested code, not 100% code coverage. There's a big difference.
&lt;/p&gt;

&lt;p&gt;
  &lt;strong&gt;(3) Don't test it until you can verify the requirements. Then thoroughly test it.&lt;/strong&gt;&lt;br /&gt;
  &lt;strong&gt;Advantage:&lt;/strong&gt; avoiding the disadvantages of options 1 and 2.&lt;br /&gt;
  &lt;strong&gt;Disadvantage:&lt;/strong&gt; verifying the requirements can be time consuming, and until you do, you have untested code.
&lt;/p&gt;

&lt;p&gt;
  If the requirements aren't clear, in my opinion, it's a tough choice. The best option is to avoid all 3 by being disciplined with testing. But honestly, I'd lean towards not testing the method. If a developer comes across a bug in the untested method, then he/she should write a test for that bug. Working on the bug also provides a good opportunity to ask questions about the requirements. If a developer needs to change the method due to a new requirement, then he/she should write a test for the change. If a developer wants to refactor the method and wants to be sure that his refactoring doesn't break anything, he might want to reconsider. Yes, poor test coverage inhibits refactoring.
&lt;/p&gt;

&lt;p&gt;
  Essentially, what I'm saying is that trying to increase test coverage by looking for untested code and writing tests for it may be harmful due to the disadvantages listed under approaches #1 and #2.
&lt;/p&gt;

&lt;p&gt;
  Keep in mind that tests can never guarantee correct requirements were implemented. But if you see a test that says 1 + 1 should be 3, you shouldn't change it until you find out more about why it's that way. Similarly, 100% coverage never guarantees that the code is well tested. But doing the minimum amount of effort to cover code makes the team less confident in the tests. I'd rather have 90% coverage, and feel that the 90% is a solid, well tested, 90%, than have 100% but feel that most of the code isn't well tested.
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/increasing-code-coverage-may-be-harmful"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Fri, 17 Oct 2008 05:30:04 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/increasing-code-coverage-may-be-harmful</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Ruby DSLs: instance_eval with delegation</title>
      <link>http://www.dcmanges.com/blog/ruby-dsls-instance-eval-with-delegation</link>
      <description>&lt;p&gt;
  I saw the warning issued on Ola's blog: &lt;a href="http://olabini.com/blog/2008/09/dont-overuse-instance_eval-and-instance_exec/"&gt;don't overuse instance_eval&lt;/a&gt;. JEG II blogged about a &lt;a href="http://blog.grayproductions.net/articles/dsl_block_styles"&gt;compromise&lt;/a&gt;, and why had &lt;a href="http://hackety.org/2008/10/06/mixingOurWayOutOfInstanceEval.html"&gt;an idea&lt;/a&gt;. But I like variation of Jim Weirich's &lt;a href="http://blade.nagaokaut.ac.jp/cgi-bin/scat.rb/ruby/ruby-core/19153"&gt;MethodDirector&lt;/a&gt;.
&lt;/p&gt;

&lt;h2&gt;how instance_eval works&lt;/h2&gt;

&lt;p&gt;
  If you're not familiar with &lt;tt&gt;instance_eval&lt;/tt&gt;, it evaluates a block of code with &lt;tt&gt;self&lt;/tt&gt; set to the object that's receiving the &lt;tt&gt;instance_eval&lt;/tt&gt; call. Here's an example.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
add_two = Proc.new { self + 2 }

puts 1.instance_eval(&amp;add_two)
#=&gt; 3

puts 2.instance_eval(&amp;add_two)
#=&gt; 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  Here's a second example using an implicit method receiver.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
call_reverse = Proc.new { reverse }

p "abc".instance_eval(&amp;call_reverse)
#=&gt; "cba"

p ["x", "y", "z"].instance_eval(&amp;call_reverse)
#=&gt; ["z", "y", "x"]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;the problem with instance_eval&lt;/h2&gt;

&lt;p&gt;
  Ola &lt;a href="http://olabini.com/blog/2008/09/dont-overuse-instance_eval-and-instance_exec/"&gt;described it&lt;/a&gt; really well, so I'm just going to quote him and then show an example.
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
  So what's the problem with it? Well, the problem is that blocks are generally closures. And you expect them to actually be full closures. And it's not obvious from the point where you write the block that that block might not be a full closure. That's what happens when you use instance_eval: you reset the self of that block into something else - this means that the block is still a closure over all local variables outside the block, but NOT for method calls. I don't even know if constant lookup is changed or not.
&lt;/p&gt;
&lt;p&gt;
  Using instance_eval changes the rules for the language in a way that is not obvious when reading a block. You need to think an extra step to figure out exactly why a method call that you can lexically see around the block can actually not be called from inside of the block.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
  Here's an example. Let's take a look at a quasi migration using &lt;tt&gt;create_table&lt;/tt&gt; and _not_ using &lt;tt&gt;instance_eval&lt;/tt&gt;.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class MyMigration &lt; MigrationExample
  def self.up
    create_table "people" do |t|
      t.string "first_name", "last_name"
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  To implement this, we could need &lt;tt&gt;t&lt;/tt&gt; to reference a &lt;tt&gt;TableDefinition&lt;/tt&gt; class that would be used to build up columns. But we could get rid of &lt;tt&gt;t&lt;/tt&gt; if we were to use &lt;tt&gt;instance_eval&lt;/tt&gt;. Because &lt;tt&gt;instance_eval&lt;/tt&gt; could change &lt;tt&gt;self&lt;/tt&gt; to reference the &lt;tt&gt;TableDefinition&lt;/tt&gt;, we could use the implicit method receiver and change the migration to look something like this.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class MyMigration &lt; MigrationExample
  def self.up
    create_table "people" do
      string "first_name", "last_name"
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  But let's take a look at the consequences of this approach. Here's a little fake migration class that just prints output.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class MigrationExample
  def self.create_table(table_name, &amp;block)
    table = TableDefinition.new table_name
    table.evaluate &amp;block
    table.create
  end
end

class TableDefinition
  def initialize(table_name, &amp;block)
    @table_name = table_name
    @columns = []
  end
  
  def evaluate(&amp;block)
    instance_eval &amp;block
  end
  
  def string(*columns)
    @columns &lt;&lt; columns
  end
  
  def create
    puts "creating the '#{@table_name}' table with columns: #{@columns.join(", ")}"
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  So here we're using &lt;tt&gt;instance_eval&lt;/tt&gt; to evaluate the block passed to &lt;tt&gt;create_table&lt;/tt&gt;. And if we run the migration, we'll see that the table gets created.
&lt;/p&gt;

&lt;pre&gt;
MyMigration.up
#=&gt; creating the 'people' table with columns: first_name, last_name
&lt;/pre&gt;

&lt;p&gt;
  But what happens if we want to use a little helper method in our migration? Let's try it by doing something completely trivial and extracting a &lt;tt&gt;name&lt;/tt&gt; method.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class MyMigration &amp;lt; MigrationExample
  def self.up
    create_table "people" do
      string name("first"), name("last")
    end
  end
  
  def self.name(which)
    "#{which}_name"
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  And now if we run the migration...
&lt;/p&gt;

&lt;pre&gt;
MyMigration.up
# NoMethodError: undefined method 'name' for #&amp;lt;TableDefinition:0x89e18 @columns=[], @table_name="people"&amp;gt;
&lt;/pre&gt;

&lt;p&gt;
  Ouch. Because &lt;tt&gt;self&lt;/tt&gt; is set to the &lt;tt&gt;TableDefinition&lt;/tt&gt; class while instance_evaling the block, our method call to &lt;tt&gt;name&lt;/tt&gt; was sent to the table definition object instead of our migration class.
&lt;/p&gt;

&lt;p&gt;
  Here's one approach to solve this problem.
&lt;/p&gt;

&lt;h2&gt;instance_eval + delegation&lt;/h2&gt;

&lt;p&gt;
  So the problem is that &lt;tt&gt;instance_eval&lt;/tt&gt; hijacks &lt;tt&gt;self&lt;/tt&gt;, making our method call to &lt;tt&gt;name&lt;/tt&gt; fail. But what if we can get the &lt;tt&gt;name&lt;/tt&gt; call sent back to the object that it would have gone to if we didn't change &lt;tt&gt;self&lt;/tt&gt;?
&lt;/p&gt;

&lt;p&gt;
  We can accomplish this by capturing what &lt;tt&gt;self&lt;/tt&gt; is before we change it with &lt;tt&gt;instance_eval&lt;/tt&gt;. Then if our class doesn't respond to a method, we'll assume it was meant for the original receiver.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
class TableDefinition
  def evaluate(&amp;block)
    @self_before_instance_eval = eval "self", block.binding
    instance_eval &amp;block
  end
  
  def method_missing(method, *args, &amp;block)
    @self_before_instance_eval.send method, *args, &amp;block
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  Looking at the &lt;tt&gt;create_table&lt;/tt&gt; block again...
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
create_table "people" do
  string name("first"), name("last")
end  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  The call to &lt;tt&gt;string&lt;/tt&gt; will be called on &lt;tt&gt;TableDefinition&lt;/tt&gt;. But the &lt;tt&gt;name&lt;/tt&gt; method call will hit method missing and be delegated back to the migration. Here's the output if we run the migration again.
&lt;/p&gt;

&lt;pre&gt;
MyMigration.up
# creating the 'people' table with columns: first_name, last_name
&lt;/pre&gt;

&lt;p&gt;
  We've removed the need for the block local variable &lt;tt&gt;t&lt;/tt&gt;, but also preserved the capability to use local helper methods.
&lt;/p&gt;

&lt;h2&gt;summary&lt;/h2&gt;

&lt;p&gt;
  This approach may be useful in some internal DSLs, but it still involves Ruby magic that may be confusing. Especially if you're trying to use instance variables. But if all you want is the ability to use helper methods and/or attribute readers, &lt;tt&gt;instance_eval&lt;/tt&gt; + delegation back to the original &lt;tt&gt;self&lt;/tt&gt; will work.
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/ruby-dsls-instance-eval-with-delegation"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Wed, 08 Oct 2008 04:59:02 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/ruby-dsls-instance-eval-with-delegation</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>The Power of Implementing Ruby in Ruby</title>
      <link>http://www.dcmanges.com/blog/the-power-of-implementing-ruby-in-ruby</link>
      <description>&lt;p&gt;
  If you're not familiar with Mixology, it's a gem that enables modules to be both mixed into and unmixed from objects, creating a great way to implement the state pattern in Ruby.
&lt;/p&gt;

&lt;h2&gt;The First Test&lt;/h2&gt;

&lt;p&gt;
  The first test for Mixology is fairly straightforward. Let's say we have an object with a &lt;tt&gt;foo&lt;/tt&gt; method that returns &lt;tt&gt;"foo from object"&lt;/tt&gt;, and a module with a &lt;tt&gt;foo&lt;/tt&gt; method that returns &lt;tt&gt;"foo from mixin"&lt;/tt&gt;. When we mix in the module, &lt;tt&gt;foo&lt;/tt&gt; should return &lt;tt&gt;"foo from mixin"&lt;/tt&gt;. We should then be able to unmix the module from the object and have the &lt;tt&gt;foo&lt;/tt&gt; method return &lt;tt&gt;"foo from object"&lt;/tt&gt; again.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
def test_unmix
  object = Class.new { def foo; "foo from object"; end }.new
  mixin = Module.new { def foo; "foo from mixin"; end }

  object.mixin mixin
  assert_equal "foo from mixin", object.foo

  object.unmix mixin
  assert_equal "foo from object", object.foo
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Getting the First Test to Pass&lt;/h2&gt;

&lt;p&gt;
  Using MRI, we're at the point where we need to drop down into C code to implement this. My C skills aren't too great, which is why &lt;a href="http://www.klankboomklang.com/"&gt;Patrick Farley&lt;/a&gt; implemented Mixology. But my Ruby skills are much better. Because Rubinius implements as much of Ruby in Ruby as possible, we can get this test to pass with 100% Ruby code.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
module Mixology
  def mixin(mod)
    reset_method_cache
    IncludedModule.new(mod).attach_to metaclass
    reset_method_cache
    self
  end
  
  def unmix(mod_to_unmix)
    last_super = metaclass
    this_super = metaclass.direct_superclass
    while this_super
      if (this_super == mod_to_unmix ||
          this_super.respond_to?(:module) &amp;&amp; this_super.module == mod_to_unmix)
        reset_method_cache
        last_super.superclass = this_super.direct_superclass
        reset_method_cache
        return self
      else
        last_super = this_super
        this_super = this_super.direct_superclass
      end
    end
    self
  end
  
  protected
  
  def reset_method_cache
    self.methods.each do |name|
      name = self.metaclass.send(:normalize_name,name)
      Rubinius::VM.reset_method_cache(name)
    end
  end
end

Object.send :include, Mixology
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  And now if we run the test, we'll have green.
&lt;/p&gt;

&lt;pre&gt;
$ rubinius test/mixology_test.rb
require 'test/unit/testcase' has been deprecated
Loaded suite test/mixology_test
Started
.
Finished in 0.024741 seconds.

&lt;span style="color: green"&gt;1 tests, 1 assertions, 0 failures, 0 errors&lt;/span&gt;
&lt;/pre&gt;

&lt;p&gt;
  It's not every day when you want implement something like unmixing a module. But if you do want to, Rubinius empowers you to do much more at the Ruby level. It's also a great way to learn more about Ruby's internals. For example, the IncludedModule class used in this implementation is how Ruby puts modules in the inheritance hierarchy for an object.
&lt;/p&gt;

&lt;h2&gt;Source on Github&lt;/h2&gt;

&lt;p&gt;
  There are still 5 pending tests before Mixology's whole test suite passes in Rubinius. If you want to give it a shot, &lt;a href="http://github.com/dan-manges/mixology/tree/master"&gt;fork my github repo&lt;/a&gt;.
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/the-power-of-implementing-ruby-in-ruby"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Sat, 04 Oct 2008 19:36:25 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/the-power-of-implementing-ruby-in-ruby</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Testing Fragment Caching</title>
      <link>http://www.dcmanges.com/blog/testing-fragment-caching</link>
      <description>&lt;h2&gt;The Risk in Fragment Caching&lt;/h2&gt;
  
&lt;p&gt;
  From &lt;a href="http://www.37signals.com/svn/posts/1185-the-need-for-speed-making-basecamp-faster"&gt;The need for speed: Making Basecamp faster&lt;/a&gt;:
&lt;/p&gt;
  
&lt;blockquote&gt;
  We've begun using Memcached in a variety of spots. Caching can be tricky with dynamic apps like Basecamp since different people often see different things, but we've implemented it carefully where it could be used to its best advantage.
&lt;/blockquote&gt;
  
&lt;p&gt;
  37signals is right. Fragment caching can be tricky. The risk is that a user sees the wrong content, but that risk can be mitigated with tests.
&lt;/p&gt;


&lt;h2&gt;Testing Fragment Caching&lt;/h2&gt;

&lt;p&gt;
  Since it's really easy for a developer or designer to make a change that causes problems with caching, it's a good idea to write a test for any pages that are using fragment caching.
&lt;/p&gt;

&lt;p&gt;
  Essentially what you need to test is that page content is exactly the same for a user regardless of whether fragments hit the cache or not. So the basic steps are:&lt;br /&gt;
(1) with caching off, capture the page content from user1's perspective&lt;br /&gt;
(2) with caching on, view the page using user2&lt;br /&gt;
(3) with caching still on, view the page using user1 and make sure the body matches the captured body from step 1.
&lt;/p&gt;

&lt;p&gt;
  You should run a test following these steps for a few combinations of user1 and user2. The more complicated the cache key is, the more tests you should have.
&lt;/p&gt;

&lt;p&gt;
  Here's an implementation using test/unit with Rails.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
def test_fragment_caching_on_some_page
  user1 = create_user :first_name =&gt; "Nick"
  user2 = create_user :first_name =&gt; "Dan"
  check_fragment_caching(user1, user2) do |user|
    @request.session[:user_id] = user.id
    get :some_page
  end
end

def check_fragment_caching(user1, user2)
  Rails.cache.clear
  ActionController::Base.perform_caching = false
  yield user1
  user_1_not_cached_body = @response.body
  
  ActionController::Base.perform_caching = true
  yield user2
  
  yield user1
  assert_equal user_1_not_cached_body, @response.body
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Example&lt;/h2&gt;

&lt;p&gt;
  Let's look at a simple example of how this works. Let's create a fragment with a static cache key.
&lt;/p&gt;

&lt;pre&gt;
&amp;lt;% cache "some_fragment" do -%&amp;gt;
  hello
&amp;lt;% end -%&amp;gt;
&lt;/pre&gt;

&lt;p&gt;
  And the test will pass.
&lt;/p&gt;

&lt;pre&gt;
Started
.
Finished in 0.147882 seconds.

&lt;span style="color: green"&gt;1 tests, 1 assertions, 0 failures, 0 errors&lt;/span&gt;
&lt;/pre&gt;

&lt;p&gt;
  But now a developer comes along and decides to greet users by name.
&lt;/p&gt;

&lt;pre&gt;
&amp;lt;% cache "some_fragment" do -%&amp;gt;
  hello &amp;lt;%= current_user.first_name %&amp;gt;
&amp;lt;% end -%&amp;gt;
&lt;/pre&gt;

&lt;p&gt;
  You can see that this will create a caching problem. If the first user to visit the page is named Dan, the fragment will be cached as "hello Dan." Then the next user, who isn't named Dan, will be greeted with "hello Dan." But the test should catch this.
&lt;/p&gt;

&lt;pre&gt;
Started
&lt;span style="color: red;"&gt;F&lt;/span&gt;
Finished in 0.15005 seconds.

  1) Failure:
test_fragment_caching_on_some_page(SomeControllerControllerTest)
method check_fragment_caching in some_controller_controller_test.rb at line 30
method test_fragment_caching_on_some_page in some_controller_controller_test.rb at line 14
&lt;span style="font-weight: bold"&gt;&amp;lt;"  hello Nick\n"&amp;gt; expected but was&lt;/span&gt;
&lt;span style="font-weight: bold"&gt;&amp;lt;"  hello Dan\n"&amp;gt;.&lt;/span&gt;
&lt;/pre&gt;

&lt;p&gt;
  Now that there is user specific information displayed inside the fragment, we'll need to update the cache key.
&lt;/p&gt;

&lt;pre&gt;
&amp;lt;% cache ["some_fragment", current_user] do -%&amp;gt;
  hello &amp;lt;%= current_user.first_name %&amp;gt;
&amp;lt;% end -%&amp;gt;
&lt;/pre&gt;

&lt;p&gt;
  And if we run the test, we're back to green.
&lt;/p&gt;

&lt;pre&gt;
Started
.
Finished in 0.149098 seconds.

&lt;span style="color: green"&gt;1 tests, 1 assertions, 0 failures, 0 errors&lt;/span&gt;
&lt;/pre&gt;

&lt;p&gt;
  Changing the cache key won't always be the answer. Sometimes you'll want to re-think the change to the page, add a dynamic element using javascript, or take a different approach altogether. But the important part is catching the caching bug quickly.
&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;
  Try to hit the all your pages that use fragment caching with different users. Try with an admin/non-admin, users under different accounts, etc. And hopefully if somebody makes a change that messes up the caching, your test will give fast feedback.
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/testing-fragment-caching"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Thu, 02 Oct 2008 14:22:31 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/testing-fragment-caching</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Reminder Tests</title>
      <link>http://www.dcmanges.com/blog/reminder-tests</link>
      <description>&lt;p&gt;
  "How are we going to remember to X if/when we Y?"
&lt;/p&gt;

&lt;p&gt;
  I ask myself that, or hear a team member ask a question like that, at least once a week.
&lt;/p&gt;

&lt;p&gt;
  The first question is: do you need to do X if/when you do Y because there's some sort of duplication? If so, eliminate the duplication. But there are situations where there's not duplication. In that case, write a test. The test either needs to check that X is always true, or it needs to detect if Y happens. Here are some examples in Ruby, but this technique applies to any language.
&lt;/p&gt;

&lt;h2&gt;Using Piston to Install Plugins&lt;/h2&gt;

&lt;p&gt;
  "How are we going to remember to use piston when we install plugins?"
&lt;/p&gt;

&lt;p&gt;
  Piston is a great tool for installing plugins. It records the repository that the plugin was installed from, along with the remote revision. One reason that this is so important is that plugins are often not released with versions like gems are. They're usually just installed from trunk (or master, for the git users). So in the future, when you want to update the plugin, it helps if you know where you installed it from and which revision it was on when you installed it.
&lt;/p&gt;

&lt;p&gt;
  So let's say you tell everybody on your development team: "when you install a plugin, use piston." Everybody sees the benefit and agrees that it's a good idea. But inevitably, somebody will install a plugin and forget. Or you'll get a new team member who doesn't know about piston. You can leave a comment somewhere - maybe a development guidelines wiki page, or a README in the vendor/plugins directory. But it would be much better to have an executable reminder. One that tells you if you forgot. So write a test that checks that all plugins were installed with piston.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
test "all plugins are installed with piston" do
  Dir.glob("#{RAILS_ROOT}/vendor/plugins/*").each do |plugin_dir|
    piston_root = `svn propget piston:root #{plugin_dir}`
    if piston_root.blank?
      raise "The #{plugin_dir} plugin was not installed with piston."
      # could leave comments here about how to install a plugin with piston
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  Presto. Now if anybody forgets to use piston, there's a test that reminds him or her.
&lt;/p&gt;

&lt;h2&gt;Updating a Dependency&lt;/h2&gt;

&lt;p&gt;
  "How are we going to remember to remove this code when we update to the next version of Rails?"
&lt;/p&gt;

&lt;p&gt;
  I recently needed to apply a bug fix from edge rails to my Rails 2.1.0 project. I thought about applying it directly to vendor/rails since the next release of Rails should include the fix. And of course, I would have written a test for it to make sure it did. But team policy was to avoid making changes directly to vendor. So I decided to make an extension to override the buggy Rails method. I didn't want the code to stick around after we updated Rails though. At that point it would become unnecessary, and only increase the chances that the fix might be incompatible with something else in Rails. So I wrote a test that would fail when we updated to the next version of Rails.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
test "this is only necessary for rails 2.1.0" do
  assert_equal "2.1.0", Rails::VERSION::STRING
  # we can remove this code once we update to the next version of rails
  # (as long as the tests for the fix still pass)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  You could use this technique for any reminder that you need to give to somebody updating a dependency.
&lt;/p&gt;

&lt;h2&gt;Database Changes&lt;/h2&gt;

&lt;p&gt;
  "How are we going to remember to use the AFTER option when we add a column?"
&lt;/p&gt;

&lt;p&gt;
  I usually use the MySQL AFTER option when adding columns to database tables so that they're alphabetized. It makes it easier to run a SELECT * query and then look for a certain column, especially if the table has more than a handful of columns. But it's easy to forget to add a column that way. Hence, a test as a reminder.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
test "columns are in alphabetical order" do
  # use add_column .... :after =&gt; "existing_column" to insert sorted
  ActiveRecord::Base.connection.tables.each do |table|
    columns = ActiveRecord::Base.connection.columns(table).map(&amp;:name)
    columns -= ["id"]
    assert_equal columns.sort, columns
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Embedded Images&lt;/h2&gt;

&lt;p&gt;
  Here's an example from &lt;a href="http://www.carepages.com"&gt;CarePages&lt;/a&gt;' domain. CarePages sends welcome e-mails on the behalf of providers and affiliates to new users. Unfortunately, we noticed that some of the welcome messages (which are stored in the database) had image tags embedded directly in them. This meant that if we ever moved the image file, we would break the welcome message. The best solution would have been to change the messages in a way that would make sure moving an image file wouldn't break the message. But under time constraints, we decided to just write a test that those images were there.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
test "embedded images are present" do
  # if any of these files move
  # welcome message that will need to be updated
  assert File.exists?("#{RAILS_ROOT}/public/images/clients/some_image.jpg")
  assert File.exists?("#{RAILS_ROOT}/public/images/clients/another_image.jpg")
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  This way, if anybody moves the image file, they also know to update the welcome message.
&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;
  Using tests for reminders is a great way to make sure you don't forget anything. But don't go overboard with it. You shouldn't have reminder tests failing daily - unless you're team is really forgetful about something they need to be doing all the time.
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/reminder-tests"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Tue, 23 Sep 2008 14:38:13 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/reminder-tests</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Rails: Performance Tuning Workflow</title>
      <link>http://www.dcmanges.com/blog/rails-performance-tuning-workflow</link>
      <description>&lt;p&gt;
  &lt;i&gt;Note: Even if you're familiar with benchmarking and profiling, take a look at the profiling section of this post. There's a nice helper method and an interesting real world example.&lt;/i&gt;
&lt;/p&gt;

&lt;p&gt;
  Improving the runtime for a page from 0.75 to 0.25 seconds may not make much of a difference to the end user's experience. But it triples the number of requests that your app servers can handle. This post covers improving performance at this level. Before you get here, you need to have your database well tuned with proper indexes, etc. Going through this workflow will make your website a little snappier and increase your overall capacity. I recently went through this process with &lt;a href="http://www.carepages.com"&gt;CarePages&lt;/a&gt;, and we were able to make significant performance improvements in one afternoon.
&lt;/p&gt;

&lt;h2&gt;CPU Time is Precious&lt;/h2&gt;

&lt;p&gt;
  The first performance bottleneck for a web app is always external resources. Most web apps use a database, so that's the common resource that can slow down your web app. But let's say your database is well indexed and handling the load of the web app fine. Also, let's assume that you don't have any other slow external resources like webservices that you call. The next bottleneck is usually the CPU if you have your own servers. If your website is running on a small slice or on shared hosting, you might hit memory limits before you max out the CPU.
&lt;/p&gt;

&lt;p&gt;
  Consider a box with 8 CPU cores and 4 GB of memory. 8 Rails processes with no slow external resources could likely max out 8 CPU cores. But for the example let's say it takes 16 Rails processes under full utilization to max out the CPU. Even if each Rails instance is using 150 MB of memory, that's only 2.4 GB of memory.
&lt;/p&gt;

&lt;p&gt;
  So if CPU time is your precious resource, you need to know how you're spending it. It helps if you have some custom logging in place, but essentially the information that you need is which page is taking up the most CPU time. It might not be your slowest page. You need to multiply the mean runtime for a page by the number of times it's hit. So if one page averages 0.2 seconds runtime, but it gets hit 20 times more frequently than a page that takes 1 second, you're spending four times as much time processing the 0.2 second page.
&lt;/p&gt;

&lt;p&gt;
  Note that when I'm referring to a page, I mean the controller and action. For example, I'm not considering /people/1 and /people/3 separate pages - they're both the people/show page.
&lt;/p&gt;

&lt;p&gt;
  At CarePages we have an Apache log that logs the controller, action, and Rails runtime. We run a script that groups the runtimes by controller and action, and then calculates the total runtime for a controller/action divided by the total runtime for all requests. What we found the first time we did this was that one of our pages was taking nearly 40% of the overall CPU time. It wasn't the slowest page, but it was the most frequently hit page. We had two other pages that were taking about 19% and 13% of the overall CPU time. This gave us a good place to start - if we could make the 40% page twice as fast, we would lower our overall CPU usage by 20%.
&lt;/p&gt;

&lt;p&gt;
  If you go through this process and find a relatively even distribution of CPU time across pages, you should look for ways to improve performance across the board rather than focusing on improving the performance of a few individual pages.
&lt;/p&gt;

&lt;h2&gt;Benchmarking&lt;/h2&gt;

&lt;p&gt;
  So now that you have a page to work on, it's time to benchmark. There are tools for Benchmarking in the form of Rails tests, and Rails 2.1 and 2.2 will have more of these tools, but I find that it's easiest to benchmark by hitting a web server. A QA environment is usually perfect for this as it will have hardware that is comparable to the hardware being used in production.
&lt;/p&gt;

&lt;p&gt;
  The goal of benchmarking to produce a baseline. We need to be able to make changes and know if those changes make things better, worse, or have no effect.
&lt;/p&gt;

&lt;p&gt;
  I usually use curl or apache bench for benchmarking. With either tool, you need to log in to your web app, navigate to the page you want to benchmark, and then grab the session cookie. Firefox's web developer toolbar provides a nice view of the cookies.
&lt;/p&gt;

&lt;p&gt;
  Once you have the cookie, hit the page using curl a few times and grep for the X-Runtime response header. I'm going to go through these steps myself right now so I can provide a real world example and get some work done while blogging. Replace the cookie and URLs that I'm using with URLs for your app.
&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;
curl --silent --head \
  --cookie "_carepages_session=eb52948f037bda387dfa9d83b6bad62986a624cf" \
  http://undisclosed.carepages.com/forums/cancer | grep X-Runtime
&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;
  Throw it in a bash while loop to hit the page a few times.
&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;
while true; do curl --silent --head \
  --cookie "_carepages_session=eb52948f037bda387dfa9d83b6bad62986a624cf" \
  http://undisclosed.carepages.com/forums/cancer | grep X-Runtime; done
&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;
  You should get a list of runtimes.
&lt;/p&gt;

&lt;pre&gt;
  X-Runtime: 0.32921
  X-Runtime: 0.33260
  X-Runtime: 0.33032
  X-Runtime: 0.33234
  X-Runtime: 0.33143
  X-Runtime: 0.33070
  X-Runtime: 0.33100
  X-Runtime: 0.32865
  X-Runtime: 0.33608
&lt;/pre&gt;

&lt;p&gt;
  You can also use apache bench, which will calculate the mean response time per request.
&lt;/p&gt;

&lt;pre&gt;
ab -c 1 -n 20 \
  -C "_carepages_session=eb52948f037bda387dfa9d83b6bad62986a624cf" \
  http://undisclosed.carepages.com/forums/cancer
&lt;/pre&gt;

&lt;p&gt;
  That command will make 20 requests, 1 at a time. Look for the time per request in the output. It should be fairly close to the X-Runtime values.
&lt;/p&gt;

&lt;pre&gt;
...
Time per request: 336.413 [ms] (mean)
...
&lt;/pre&gt;

&lt;p&gt;
  Hopefully you get fairly consistent response times. If not, you'll need to keep the inconsistency in mind while making changes.
&lt;/p&gt;

&lt;p&gt;
  Now you have a baseline. In my output, I'm hitting the /forums/cancer page for CarePages. It consistently takes around 0.33 seconds to process.
&lt;/p&gt;

&lt;h2&gt;Profiling&lt;/h2&gt;

&lt;p&gt;
  The next question is why is this page taking X seconds to process? You need to profile the code to find out where you're spending those CPU cycles. To do this you'll need to install the ruby-prof gem.
&lt;/p&gt;

&lt;p&gt;
  It's easiest to start by profiling the entire processing for a request, and then making it more focused only if necessary. I use an around_filter in my ApplicationController to make profiling easier.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
require "ruby-prof"
class ApplicationController &lt; ActionController::Base
  around_filter :profile
  
  def profile
    return yield if params[:profile].nil?
    result = RubyProf.profile { yield }
    printer = RubyProf::GraphPrinter.new(result)
    out = StringIO.new
    printer.print(out, 0)
    response.body.replace out.string
    response.content_type = "text/plain"
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  This allows you to profile a request by tacking &lt;tt&gt;?profile=true&lt;/tt&gt; on to the end of a URL. The response will then contain the profiling results instead of the normal response body. You may want to add a line of code so that this is only available in non-production environments. You also could update this code to embed the profiling in the response body rather than replacing the entire body with it.
&lt;/p&gt;

&lt;p&gt;
  I'm going to use this to profile the cancer forum page that I benchmarked by opening &lt;tt&gt;http://undisclosed.carepages.com/forums/cancer?profile=true&lt;/tt&gt; in my browser. If you do the same for your web app, you should get the profiling results back in plain text call graph form.
&lt;/p&gt;

&lt;p&gt;
  Here's a snippet of output from the profiling that I just did that looks quite suspicious. (I removed a few columns to make the output narrower).
&lt;/p&gt;

&lt;pre&gt;
--------------------------------------------------------------------------------
                      0.55      96/96     Rsm::SeoUrls::InstanceMethods#to_param
  &lt;strong&gt;65.48%   0.00%      0.55         96     Rsm::SeoUrls::InstanceMethods#seo_urls_permalink&lt;/strong&gt;
                      0.00     96/281     String#tr
                      0.00     96/408     String#downcase
                      &lt;strong&gt;0.55    192/192     ActiveRecord::Base#attributes&lt;/strong&gt;
                      0.00     96/283     String#+
                      0.00    96/1914     String#strip
                      0.00  192/12138     Hash#[]
                      0.00    96/2035     String#gsub
                      0.00   96/10887     Kernel#nil?
                      0.00    96/7006     String#to_s
                      0.00      96/96     String#squeeze
                      0.00    192/192     Topic#attribute_for_url
--------------------------------------------------------------------------------
&lt;/pre&gt;

&lt;p&gt;
  The percentage in the left column is the percent of the total processing time that a certain method took. You want to look for anything that jumps out as taking longer than you think it should.
&lt;/p&gt;

&lt;p&gt;
  This chunk of profiling means that 65.48% of the time spent processing /forums/cancer was inside the &lt;tt&gt;Rsm::SeoUrls::InstanceMethods#seo_urls_permalink&lt;/tt&gt; method. Spending more than half of the processing time generating permalinks is way too long.
&lt;/p&gt;

&lt;p&gt;
  Let's take a look at the &lt;tt&gt;seo_urls_permalink&lt;/tt&gt; method from the seo_urls plugin.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
def seo_urls_permalink
  if !self.attributes[attribute_for_url]
    begin
      string=self.title
    rescue
      begin
        string=self.name
      rescue
        raise("No attribute was specified for seo_urls to use and 'name' and 'title' weren't available")
      end
    end
  else
    string=self.attributes[attribute_for_url]
  end
  if string.nil?
    return ""
  else
    t = "-"+(string.to_s.downcase.strip.gsub(/[^-_\s[:alnum:]]/, '').squeeze(' ').tr(' ', '-'))
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  There are definitely a few inefficiencies here. The first is the multiple rescues. They're pointless - Ruby's &lt;tt&gt;respond_to?&lt;/tt&gt; method should be used instead. The other inefficiency is the call to attributes. We only need to access one attribute, but we're accessing the entire hash. This wouldn't be a problem, except that Rails does typecasting when accessing the attributes. In particular the time zone conversion on time columns is a little slow. Let's rewrite this method.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
def seo_urls_permalink
  attr = attribute_for_url
  attr = :title if attr.nil? &amp;&amp; respond_to?(:title)
  attr = :name if attr.nil? &amp;&amp; respond_to?(:name)
  unless attr
    raise("No attribute was specified for seo_urls to use and 'name' and 'title' weren't available")
  end
  string = send(attr)
  return "" if string.nil?
  "-"+(string.to_s.downcase.strip.gsub(/[^-_\s[:alnum:]]/, '').squeeze(' ').tr(' ', '-'))
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
  I ran the tests for the seo_urls plugin, and they passed. It's time to find out if this change makes a difference by running the benchmarks again.
&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;
while true; do curl --silent --head \
  --cookie "_carepages_session=eb52948f037bda387dfa9d83b6bad62986a624cf" \
  http://undisclosed.carepages.com/forums/cancer | grep X-Runtime; done
&lt;/pre&gt;
&lt;/p&gt;

&lt;pre&gt;
  X-Runtime: 0.07943
  X-Runtime: 0.16852
  X-Runtime: 0.07982
  X-Runtime: 0.16367
  X-Runtime: 0.07924
  X-Runtime: 0.16349
  X-Runtime: 0.07905
  X-Runtime: 0.16404
  X-Runtime: 0.07916
  X-Runtime: 0.16441
  X-Runtime: 0.07875
&lt;/pre&gt;

&lt;p&gt;
  Awesome. The processing time is now half of what is was before. I'll submit a patch for the seo_urls plugin. Interestingly, some response times are quite a bit faster than others. I may be hitting the point where garbage collection is kicking in more during some requests than during others.
&lt;/p&gt;

&lt;p&gt;
  Here's the new profiling for my /forums/cancer page, looking at the &lt;tt&gt;seo_urls_permalink&lt;/tt&gt; method.
&lt;/p&gt;

&lt;pre&gt;
--------------------------------------------------------------------------------
                      0.01        96/96     Rsm::SeoUrls::InstanceMethods#to_param
   &lt;strong&gt;4.76%   0.00%      0.01           96     Rsm::SeoUrls::InstanceMethods#seo_urls_permalink&lt;/strong&gt;
                      0.00       58/333     Kernel#send-3
                      0.00      96/2207     String#to_s
                      0.00        96/96     String#squeeze
                      0.01        10/13     Kernel#send-5
                      0.00       96/282     String#tr
                      0.00       96/217     String#downcase
                      0.00       96/283     String#+
                      0.00       96/186     String#strip
                      0.00      96/2041     String#gsub
                      0.00      96/1766     Kernel#nil?
                      0.00      192/192     ActiveRecord::AttributeMethods#respond_to?
                      0.00       28/578     Kernel#send-2
--------------------------------------------------------------------------------
&lt;/pre&gt;

&lt;p&gt;
  I'm now spending &lt;strong&gt;4.76%&lt;/strong&gt; of the total processing time in &lt;tt&gt;seo_urls_permalink&lt;/tt&gt;, compared to &lt;strong&gt;65.48%&lt;/strong&gt; before.
&lt;/p&gt;

&lt;h2&gt;Repeat&lt;/h2&gt;

&lt;p&gt;
  Continue repeating this process until the processing time distribution per controller and action is mostly even. At that point, it's time to look to improve the performance of the pages with the slowest mean processing time. Or you could look for ways to improve the performance of every page.
&lt;/p&gt;

&lt;p&gt;
  Don't get too caught up on the distribution though. If you have a page that takes 20% of the overall processing for your site, but you don't see any easy wins, take a look at the next page. Doubling the speed of page that takes 10% of the overall time will still increase capacity by 5%.  
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/rails-performance-tuning-workflow"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Sun, 21 Sep 2008 08:07:32 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/rails-performance-tuning-workflow</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Asset Versioning in Rails</title>
      <link>http://www.dcmanges.com/blog/asset-versioning-in-rails</link>
      <description>&lt;p&gt;&lt;tt&gt;
  &amp;lt;script src="/javascripts/jquery.js&lt;strong&gt;?1212761793&lt;/strong&gt;" type="text/javascript"&amp;gt;&amp;lt;/script&amp;gt;
&lt;/tt&gt;&lt;/p&gt;

&lt;blockquote&gt;
  "What are those numbers Rails puts after my image, css, and javascript files?"&lt;br /&gt;
  &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;mdash; Some Rails developer
&lt;/blockquote&gt;

&lt;p&gt;
That's the time (cast to an integer) that the file was last modified. Rails tags assets with a timestamp to solve potential issues with browser caching and to improve page load time.
&lt;/p&gt;

&lt;p&gt;
Whenever the file changes, the query string will change, causing browsers to download a fresh version of the asset instead of using a cached copy. This ensures that users will never be using an old css/js/image file. Because the query string will change any time the file changes, you can set a far future expires header, telling the browser that it can cache the asset indefinitely.&lt;br /&gt;
&lt;/p&gt;

&lt;p&gt;
Rails takes care of the query string, but you need to set up the expires header in your web server config.
&lt;/p&gt;

&lt;h2&gt;Setting a Far Future Expires Header&lt;/h2&gt;

&lt;p&gt;
The Rails documentation provides the following sample configuration to set the expires header in Apache.
&lt;/p&gt;

&lt;pre&gt;
ExpiresActive On
&amp;lt;FilesMatch "\.(ico|gif|jpe?g|png|js|css)$"&amp;gt;
  ExpiresDefault "access plus 1 year"
&amp;lt;/FilesMatch&amp;gt;
&lt;/pre&gt;

&lt;p&gt;
But there could be a problem with setting the expires header this way. If you have an image/css/js file that does not have a version, when you update that file, your users will still be using the old copy that's cached in their browser. Because the response header told the browser to cache the file as long as it wants to, it could be a while before the user gets the new version.
&lt;/p&gt;

&lt;p&gt;
You really only want to set the expires header when serving up versioned assets. Here's one way to do that with Apache.
&lt;/p&gt;

&lt;pre&gt;
RewriteCond %{REQUEST_URI} (css|js|jpe?g|png|gif|ico)$ [NC]
RewriteCond %{QUERY_STRING} ^[0-9]+$
RewriteRule ^(.*)$ $1 [E=set_expires_header:true,L]

Header add Expires "Wed, 04 Aug 2010 16:46:21 -0500" env=set_expires_header
&lt;/pre&gt;

&lt;p&gt;
I'm not an Apache guru, so there may be a more elegant way to do this. Also, on the project where I'm doing this, the Apache config file is generated. We set the expires header to 2 years from the time of the file generation. I don't know of a way to dynamically set the date otherwise.
&lt;/p&gt;

&lt;p&gt;
We can use curl to check that requesting the image with the asset version will set the expires header.
&lt;/p&gt;

&lt;pre&gt;
$ curl --head http://localhost:9999/images/&lt;strong&gt;rails.png?1213412&lt;/strong&gt;
HTTP/1.1 200 OK
Date: Fri, 05 Sep 2008 02:34:25 GMT
Server: Apache/2.2.8 (Unix) mod_ssl/2.2.8 OpenSSL/0.9.7l Phusion_Passenger/2.0.2
Last-Modified: Thu, 04 Sep 2008 13:40:13 GMT
Accept-Ranges: bytes
Content-Length: 6646
&lt;strong&gt;Expires: Wed, 04 Aug 2010 16:46:21 -0500&lt;/strong&gt;
Content-Type: image/png
&lt;/pre&gt;

&lt;p&gt;
And if we request the image without the version, there's no expires header.
&lt;/p&gt;

&lt;pre&gt;
$ curl --head http://localhost:9999/images/&lt;strong&gt;rails.png&lt;/strong&gt;
HTTP/1.1 200 OK
Date: Fri, 05 Sep 2008 02:34:13 GMT
Server: Apache/2.2.8 (Unix) mod_ssl/2.2.8 OpenSSL/0.9.7l Phusion_Passenger/2.0.2
Last-Modified: Thu, 04 Sep 2008 13:40:13 GMT
Accept-Ranges: bytes
Content-Length: 6646
Content-Type: image/png
&lt;/pre&gt;

&lt;h2&gt;Forcing the Browser to Update Its Cache&lt;/h2&gt;

&lt;p&gt;
You want to make sure that whenever you update your asset files, your users aren't using a stale cached copy. Rails takes care of this, because whenever the query string after the file changes, the browser will treat it like a new file and download it. I read that (according to the HTTP spec) &lt;a href="http://www.thinkvitamin.com/features/webapps/serving-javascript-fast"&gt;Safari won't cache files that use a query string&lt;/a&gt;, but I did some testing with Safari 3.1.2 on OS X and that doesn't appear to be true.
&lt;/p&gt;

&lt;p&gt;
The only thing that you have to do to update the query string is modify and file and possibly restart your app server. As of Rails 2.1, the query string won't change unless you restart your server. Older versions of Rails will update it without the restart. In practice, the Rails 2.1 behavior is fine since you only update files when doing deployments, and you're restarting your server then anyway.
&lt;/p&gt;

&lt;p&gt;
Even if you're not setting the far-future expires header, it's a good idea to version your assets. Browsers will cache files without any expires header for a while, and some users are going to be behind proxies that have their own crazy caching strategy.
&lt;/p&gt;

&lt;p&gt;
There's a few more good practices with asset versioning that Rails doesn't do for you - I'll be blogging about them soon.  
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/asset-versioning-in-rails"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Sat, 06 Sep 2008 19:47:31 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/asset-versioning-in-rails</guid>
      <author>Dan Manges</author>
    </item>
    <item>
      <title>Deploying from a Subversion Tag using Vlad</title>
      <link>http://www.dcmanges.com/blog/deploying-from-an-svn-tag-using-vlad</link>
      <description>&lt;p&gt;
On the Rails project I'm currently working on, the team decided to use &lt;a href="http://rubyhitsquad.com/Vlad_the_Deployer.html"&gt;Vlad&lt;/a&gt; for deployment. If you're not familiar with Vlad, it's just like Capistrano with 2 big architectural differences.
&lt;/p&gt;

&lt;p&gt;
(1) Vlad uses the command line ssh client instead of using net/ssh.&lt;br /&gt;
(2) Vlad uses Rake for tasks, and Capistrano has its own task system.
&lt;/p&gt;

&lt;p&gt;
Deploying from a subversion tag using Capistrano is pretty easy: all you have to do is set the repository to the tag you want to deploy from. We can use the same approach in Vlad, but we need an additional step.
&lt;/p&gt;

&lt;p&gt;
Before we get there, the first step is to write a task to prompt for the tag to use.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
namespace :vlad do
  task :set_repository do
    tag = Readline.readline("tag to deploy (or trunk): ")
    if tag == "trunk"
      set :repository, "http://repo/trunk/"
    else
      set :repository, "http://repo/tags/#{tag}"
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
We then need to make the update task depend on the &lt;tt&gt;set_repository&lt;/tt&gt; task.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
namespace :vlad
  remote_task :update =&gt; %w[set_repository]
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
Due to how Vlad checks out the code, there's one more step. Vlad makes deployments faster by having an scm directory where the code is checked out. It does a checkout to the scm directory and exports from there to a release directory. The problem is if we had previously deployed trunk, but are now trying to deploy a tag, Vlad will try to checkout the tag on top of the trunk checkout, which subversion complains about.
&lt;/p&gt;

&lt;p&gt;
&lt;tt&gt;svn: '.' is already a working copy for a different URL&lt;/tt&gt;
&lt;/p&gt;

&lt;p&gt;
We can fix this by modifying the update task to do an svn switch on the scm directory.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
namespace :vlad do
  namespace :svn do
    remote_task :switch, :roles =&gt; [:app] do
      run "if [[ -d #{scm_path}/.svn ]]; then cd #{scm_path} &amp;&amp; svn switch #{repository}; fi"
    end
  end
  
  remote_task :update =&gt; %w[set_repository svn:switch]
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
The if statement is there so that this task doesn't fail on the very first checkout to the scm directory.
&lt;/p&gt;

&lt;p&gt;
I looked through the code, but couldn't find a built-in way to make this easier. But perhaps I overlooked something. This is using Vlad 1.2.0.
&lt;/p&gt;
&lt;br /&gt;&lt;a href="http://www.dcmanges.com/blog/deploying-from-an-svn-tag-using-vlad"&gt;comments&lt;/a&gt; | &lt;a href="http://twitter.com/dan_manges"&gt;twitter&lt;/a&gt;</description>
      <pubDate>Wed, 27 Aug 2008 03:18:15 GMT</pubDate>
      <guid>http://www.dcmanges.com/blog/deploying-from-an-svn-tag-using-vlad</guid>
      <author>Dan Manges</author>
    </item>
  <feedburner:awareness xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://api.feedburner.com/awareness/1.0/GetFeedData?uri=dcmanges</feedburner:awareness></channel>
</rss>
