<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="http://feeds.feedburner.com/~d/styles/atom10full.xsl" type="text/xsl" media="screen"?><?xml-stylesheet href="http://feeds.feedburner.com/~d/styles/itemcontent.css" type="text/css" media="screen"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:thr="http://purl.org/syndication/thread/1.0" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">
    <title>Nimble Method</title>
    
    <link rel="alternate" type="text/html" href="http://blog.pluron.com/" />
    <id>tag:typepad.com,2003:weblog-497997</id>
    <updated>2008-07-14T04:42:40-07:00</updated>
    
    <generator uri="http://www.typepad.com/">TypePad</generator>
    <link rel="self" href="http://feeds.feedburner.com/pluron" type="application/atom+xml" /><entry>
        <title>Why You Should Use 'Cache-Control: public' for Caching to Work with SSL</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/335027150/why-you-should.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/07/why-you-should.html" thr:count="4" thr:updated="2008-07-16T15:46:55-07:00" />
        <id>tag:typepad.com,2003:post-52667646</id>
        <published>2008-07-14T04:42:40-07:00</published>
        <updated>2008-07-16T15:46:55-07:00</updated>
        <summary>We've been using long Expires and Cache-Control: max-age headers to mark our javascripts and css as browser-cacheable for quite some time. This way the browser only does full GETs on these once, and avoids conditional GETs except on page refresh....</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        <category scheme="http://www.sixapart.com/ns/types#category" term="Rails Performance" />
        
        
<content type="xhtml" xml:lang="en-US" xml:base="http://blog.pluron.com/"><div xmlns="http://www.w3.org/1999/xhtml"><p>We've been using long <i>Expires</i> and <i>Cache-Control: max-age</i>
headers to mark our javascripts and css as browser-cacheable for quite
some time.  This way the browser only does full GETs on these once,
and avoids conditional GETs except on page refresh.  This only
requires a few lines of configuration in Rails (asset timestamps and
asset packaging) and nginx and generally works well.</p>

<p>Except when it does not.  We've had some bug reports that in some
cases under SSL these files were not cached at all.  Meaning, just
going to a different page in our application would make browser do an
unconditional GET to refetch css and javascript.  Naturally, this
would hurt the performance.</p>

<p>Now, SSL in itself makes things worse.  Firefox only caches SSL
content in memory not on disk, meaning if the user closes the browser
the cache goes away.  But the reported behavior was worse than that --
no caching at all.</p>

<p>It took us a while, but we did manage to chase it down.  It seems that
Firefox divides SSL content into page marked with <i>Cache-Control:
public</i>, which have priority for caching, and the rest.  When you
open enough tabs, say 50+, with enough rich pages in Firefox, its
in-memory cache fills up and refuses to cache non-public SSL content.
We haven't had time to fully chase it down in the FF codebase, but
what's likely to happen is that FF actually does put in into cache,
then realizes that cache is full, looks for pages to evict, and right
away evicts the newly added content.  Since SSL content is not cached
on hard disk, once the memory cache is full, the non-pubic SSL files
are not cached at all. (Note that's just a hypothesis, we'd be most
curious to know what actually happens and why.)</p>

<p>The server-side workaround is to add <i>Cache-Control: public</i> to
all your SSL content you want cached.  We do:</p>

<pre><code># nginx configuration for static content  
location /static {
    expires 1y;
    add_header Cache-Control public;
}
</code></pre>

<p>This bug is present in Firefox 2 and 3, but as a user you can
configure them to work around the problem by <a href="http://kb.mozillazine.org/Browser.cache.memory.capacity">setting
<em>browser.cache.memory.capacity</em></a>
to increase the size of memory cache or using
<a href="http://kb.mozillazine.org/Browser.cache.disk_cache_ssl"><em>browser.cache.disk_cache_ ssl</em></a>
to enable disk cache for SSL pages. The default 24M memory cache size
for systems with 2G of RAM is really small, especially with FF3 being
able to handle hundreds of tabs well.  Note that the disk_cache
option works only on Firefox 3 because of
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=345181">some</a>
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=262116">bugs</a> in earlier
browser versions.</p>

<p>Small remark for <a href="http://www.acunote.com">Acunote</a> users - you don't
have to do anything about this. We enabled <i>Cache-Control:
public</i> and your Firefox will cache javascript and css files no
matter how many tabs you have.</p>
<xhtml:img xmlns:xhtml="http://www.w3.org/1999/xhtml" src="http://feeds.feedburner.com/~r/pluron/~4/335027150" height="1" width="1" /></div></content>


    <feedburner:origLink>http://blog.pluron.com/2008/07/why-you-should.html</feedburner:origLink></entry>
    <entry>
        <title>The Road to Hell Is Paved With Caching</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/325059615/hell-is-paved-w.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/07/hell-is-paved-w.html" thr:count="1" thr:updated="2008-07-02T15:19:52-07:00" />
        <id>tag:typepad.com,2003:post-52117060</id>
        <published>2008-07-02T10:32:39-07:00</published>
        <updated>2008-07-02T15:19:52-07:00</updated>
        <summary>In [Acunote](http://www.acunote.com) we are heavily using fragment caching. We cache whenever we can and whatever we can. Sounds like a great idea to do? Well, almost... Sometimes caching hurts and here's why. ## Prehistory ## Acunote is a project management...</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        
        
<content type="html" xml:lang="en-US" xml:base="http://blog.pluron.com/">
&lt;div xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;p&gt;In &lt;a href="http://www.acunote.com"&gt;Acunote&lt;/a&gt; we are heavily using fragment caching. We cache whenever we can and whatever we can. Sounds like a great idea to do? Well, almost... Sometimes caching hurts and here's why.&lt;/p&gt;

&lt;h2&gt;Prehistory&lt;/h2&gt;

&lt;p&gt;Acunote is a project management tool and therefore the most prominent page in Acunote is the task list in the current sprint. The page itself shows some information specific to the user who logged in and some information that is shared among the users within the user's organization.&lt;/p&gt;

&lt;p&gt;We can cache the shared part of the page in the fragment cache taking date and page filters into account. The code roughly looks like this:&lt;/p&gt;

&lt;pre&gt;
&lt;%- cache(:part =&gt; "#{filters}_#{DateUtils::today}") do -%&gt;
    &lt;%= render :partial =&gt; '...' -%&gt;
&lt;%- end -%&gt;
&lt;/pre&gt;

&lt;p&gt;Using filesystem caching store we end up having this (simplified) cache directory layout:&lt;/p&gt;

&lt;pre&gt;
 - organization1.acunote.com
   - sprints
     - show.part=filter1.date.cache
     - show.part=filter2.date.cache
     - show.part=filter3.date.cache
 - organization2.acunote.com
   - sprints
     - show.part=filter1.date.cache
     - show.part=filter2.date.cache
     - show.part=filter3.date.cache
&lt;/pre&gt;

&lt;h2&gt;Problem&lt;/h2&gt;

&lt;p&gt;Problems start when we try to expire caches. We can't expire by url or by hash because we want to expire all cache parts (for all possible filters and for all dates). Therefore we use regexp:&lt;/p&gt;

&lt;pre&gt;
expire_fragment(%r{show.part=.*})
&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;That turned into a problem in production&lt;/strong&gt;. The reason is that expire_fragment in Rails &lt;strong&gt;searches the whole cache directory recursively&lt;/strong&gt; and removes files with names matching the regular expression. On machines with local disks that's usually fast, but on network filesystems or on shared disk cluster filesystems (like GFS in our case) stat'ing lots of files can be &lt;strong&gt;really&lt;/strong&gt; slow. To make things worse, the performance of stat call on GFS really depends on the phase of the moon or something like that ;)&lt;/p&gt;

&lt;p&gt;Our logs showed that operations that would usually take less than a second took on occasion took 70 seconds! They were so slow so I could actually log in to our production servers, find the process taking too much time to complete and attach strace to it. Strace blessed me, immediately showing multiple stat's for files in the cache directory.&lt;/p&gt;

&lt;h2&gt;Solution&lt;/h2&gt;

&lt;p&gt;Longer term we'll switch to a more scalable fragment caching strategy.  There is a good reason why high-performance caches do not support fancy invalidation, and there are known way to code to their more restricted interface.  Meanwhile, immediate solution was really simple. We only had to expire fragments in specific directories and to make that easier, I wrote a little extension to Rails' fragment caching code:&lt;/p&gt;

&lt;pre&gt;
module ActionController
  module Caching
    module Fragments

    #dir is the cache path relative to the cache root
    def expire_matched_fragment_in_dir(dir, regexp, options = nil)
      return unless perform_caching
      self.class.benchmark("Expired fragments in dir matching: #{regexp.source}") do
        fragment_cache_store.delete_matched_in_dir(dir, regexp, options)
      end
    end

    class UnthreadedFileStore

      def delete_matched_in_dir(dir, matcher, options = nil)
        path = @cache_path + dir
        return unless File.exist?(path) #it's ok to not have the cache dir
        search_dir(path) do |f|
          if f =~ matcher
          begin
            File.delete(f)
          rescue SystemCallError =&gt; e
            # If there's no cache, then there's nothing to complain about
          end
          end
         end
        end
      end

    end

  end
end

#include only if you use cache test plugin
module Cosinux
  module FragmentCacheTest
    class TestStore
      def delete_matched_in_dir(dir, matcher, options = nil)
        @deleted_matchers.push(matcher)
      end
    end
  end
end
&lt;/pre&gt;

&lt;h2&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;Monitoring the performance of production application is sometimes even more important than profiling it on the development machines. We already had monitoring system in place so we could detect when our application got slower, figure out the root cause and and fix the problem.&lt;/p&gt;

&lt;p&gt;Another thing I highly recommend is of course &lt;b&gt;strace&lt;/b&gt;. You may indeed see that your application is doing something so weird you'd never think of just looking at the code or at the profiler. So, I now declare strace to be officially added into my own arsenal of invaluable profiling tools.&lt;/p&gt;
&lt;/div&gt;
&lt;img src="http://feeds.feedburner.com/~r/pluron/~4/325059615" height="1" width="1"/&gt;</content>


    <feedburner:origLink>http://blog.pluron.com/2008/07/hell-is-paved-w.html</feedburner:origLink></entry>
    <entry>
        <title>Performance Freak's View on RailsConf 2008</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/320438405/performance-fre.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/06/performance-fre.html" thr:count="4" thr:updated="2008-07-07T18:50:42-07:00" />
        <id>tag:typepad.com,2003:post-50793570</id>
        <published>2008-06-26T04:01:39-07:00</published>
        <updated>2008-07-07T18:50:43-07:00</updated>
        <summary>RailsConf is over and it's about time for reflections now. Two hot topics this year dominated the conference - we've got a strong presence from people working on alternative Ruby implementations and lots of presentations on scaling and performance. In...</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        <category scheme="http://www.sixapart.com/ns/types#category" term="Ruby on Rails" />
        
        
<content type="xhtml" xml:lang="en-US" xml:base="http://blog.pluron.com/"><div xmlns="http://www.w3.org/1999/xhtml"><p>RailsConf is over and it's about time for reflections now. Two hot topics this year dominated the conference - we've got a strong presence from people working on alternative Ruby implementations and lots of presentations on scaling and performance. In short, my two conclusion on those topics are:</p>

<ul>
<li>one and only one MRI alternative now really works</li>
<li>Rails community focuses on scaling rather than performance</li>
</ul>

<p>Read on and I'll tell you what works and what to do if you want faster and not larger Rails.</p>

<h2>Alternative Ruby</h2>

<p>The current situation with alternative ruby implementations reminds me of the lions pride. The lion king (read MRI) is old and weak, but it's still strong enough to outperform the subadults. Despite that, some of the youngsters look promising, some them look cool and some look as undecidable. My personal opinion here is that promising implementations take existing VM and implement Ruby on top of them, cool implementation do all on their own and undecidable ones are not open source. Ok, enough generalizations, this topic deserves somebody to talk in details, so here are my stories on JRuby, Rubinius, Ruby 1.9, Iron Ruby and MagLev. </p>

<h3>JRuby Story</h3>

<p>I've been watching JRuby since its inception. I remember listening to <a href="http://headius.blogspot.com">Charles Nutter</a> back in 2006 at RailsConf Europe when he demonstrated the first JRuby version that could run Rails. Cool, I said to myself and continued with MRI.</p>

<p>I also remember myself sitting at Charles' tutorial last year trying to get my application running under JRuby. At that time I spent 3 hours to get the app almost running - all <a href="http://www.acunote.com">Acunote</a> functionality eventually worked except for burndowns because of broken RMagick. And of course our performance benchmarks showed the application became 3-5 times slower.</p>

<p>This year was a breakthrough. I was sitting through one of the presentations about scaling Rails when I thought that it's a good idea to try JRuby once again. So I did. In 15 minutes I got all JRuby stuff and required dependencies installed and Acunote running. That was a real "wow starts now" moment :) All code we have just worked. Ok, what's about the performance you might ask. I ran Acunote benchmarks and it turned out that JRuby shows <em>exactly the same performance as MRI</em>! And that's using old Java5 Client VM, postgres-pr driver written in Ruby and only 3 requests to warm up the VM. Once I'll get back home, I'll try using JDBC driver, recent JVM and issue more requests for benchmarking. The gut feeling is that JRuby will be faster in that case, watch for my next blog post if you're curious ;)</p>

<h3>Rubinius and Ruby 1.9 Story</h3>

<p>These guys have all the fun for sure, but they will simply need more time to implement their VM's right. As you see from my previous story, three years was enough to get JRuby really working. And bear in mind, they didn't have to write VM.</p>

<p>Despite that, I personally become more and more interested in Rubinius. As you might know, I'm <a href="http://kdevelop.org">KDevelop IDE</a> developer and one of the guys who worked on Ruby support for KDevelop. Java support in Eclipse is so cool just for one reason - they have compiler built in that knows <em>everything</em> about your code. Rubinius looks like a perfect tool to do exactly this for KDevelop. It may be able to load all the code and keep it constantly running as you work on the project and IDE would be able to recompile changed bits of the code on the fly. This Smalltalk-like way is probably the only way IDE can know about all symbols in the code written in dynamic language. I'm definitely looking forward having some free time to play with that.</p>

<h3>MagLev and IronRuby Story</h3>

<p>MagLev today is even less than JRuby in 2006. It's still more like a proof-of-concept that you <em>can</em> run Ruby on Smalltalk VM rather than a product in development. It was quite cool to see Smalltalk-like object caches and stores working with Ruby. As somebody said, seeing two irb's working with the same global state was a mind-blowing experience :)</p>

<p>Anyway, during the next 3-4 years we'll see whether they survive and produce something useful. The only issue in my opinion with MagLev is that it is closed source. These days you have to have really really good product to compete with open source in the arena of languages, compilers and VM's. Time will tell whether MagLev will have that advantage.</p>

<p>Microsoft's IronRuby is slightly more mature (maybe because it runs Rails ;)) but still has a long way to go. IronRuby guys also did have some cool stuff to show us at their presentation. Their mind-blowing thing was the same Ruby application running on server (Rails app) and client (Ruby in Silverlight). Sounds cool, let's see where that will go.</p>

<h2>Scaling vs Performance</h2>

<p>I thought performance was going to be the hot topic this year. I was proven wrong. The majority of Rails crowd now thinks it's easier to "scale" rather than to "optimize". Yeah, good old "add more hardware" approach with some new techniques added to make that process easier.</p>

<p><a href="http://www.koziarski.net/">Michael Koziarski</a> was probably the only one to speak about performance and tell the right thing. The idea is that it's always possible to improve something in Rails application by optimizing it or even optimizing Rails itself and the process to do that is easy - <em>measure</em> to find what's slow, <em>fix</em> it and <em>measure</em> again. </p>

<p>This measure-fix-measure is not a revelation and there're great tools to do that like ruby-prof and KCachegrind (see my <a href="http://blog.pluron.com/2008/02/memory-profilin.html">previous blog post on profiling</a>). I just wish more people used it.</p>

<p>After RailsConf Jeremy Kemper did some great work in <a href="http://weblog.rubyonrails.org/2008/6/25/living-on-the-edge-or-what-s-new-in-edge-rails-2-performance-improvements">optimizing Rails further</a>. Also it's cool to see that Jeremy added <a href="http://weblog.rubyonrails.org/2008/6/20/living-on-the-edge-or-what-s-new-in-edge-rails-1-api-changes-and-performancetests">performance test generators into Rails</a>. I do hope that those tests will help people to make performance improvement the integral part of Rails application development process.</p>

<p>Speaking about profiling, Scott Barron and Chad Humphries from EdgeCase did a nice presentation about using DTrace with Ruby. DTrace is what you can use instead of ruby-prof (or together with ruby-prof) on development machines for regular profiling. But more interestingly, thanks to its low resource footprint, DTrace can become the real-time profiling solution for your production app (in case you deploy on Leopard or Solaris). This way you would be able to find slowdowns that happen rarely or happen only under heavy load on production machines. I only wish I had such tool available on Linux (to profile <a href="http://www.acunote.com">Acunote</a> of course).</p>

<h2>Final Thanks</h2>

<p>Wrapping up this overview, I'd like to thank all speakers for great talks, especially <a href="http://yehudakatz.com/">Yehuda Katz</a> (DataMapper presentation), <a href="http://bitsweat.net/">Jeremy Kemper</a> (Rails 2.1 keynote), <a href="http://www.koziarski.net/">Michael Koziarski</a> (Rails performance), <a href="http://www.wayfargone.com/brainfloss/">Adam Pisoni</a> (Skynet) and <a href="http://www.misuse.org/science/">Stephen Midgley</a> (Complex searching in Rails) for the in-depth high-quality technical talks I've enjoyed so much.</p>

<p>I had a great time at RailsConf and hope you did that too, see you next year.</p>
<xhtml:img xmlns:xhtml="http://www.w3.org/1999/xhtml" src="http://feeds.feedburner.com/~r/pluron/~4/320438405" height="1" width="1" /></div></content>


    <feedburner:origLink>http://blog.pluron.com/2008/06/performance-fre.html</feedburner:origLink></entry>
    <entry>
        <title>Things we look forward to at RailsConf 2008</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/300870434/things-we-look.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/05/things-we-look.html" thr:count="2" thr:updated="2008-06-01T23:17:09-07:00" />
        <id>tag:typepad.com,2003:post-50570446</id>
        <published>2008-05-29T16:45:18-07:00</published>
        <updated>2008-06-01T23:17:10-07:00</updated>
        <summary>Yes, Gleb and I are coming again to RailsConf this year. We are expecting to listen to good talks and to meet a lot of cool people. There're definitely some interesting presentation schedule for this year. Of course we're interested...</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        
        
<content type="xhtml" xml:lang="en-US" xml:base="http://blog.pluron.com/"><div xmlns="http://www.w3.org/1999/xhtml"><p>Yes, Gleb and I are coming again to RailsConf this year.  We are expecting to listen to good talks and to meet a lot of cool people.</p>

<p>There're definitely some interesting presentation schedule for this year. Of course we're interested in what <a href="http://en.oreilly.com/rails2008/public/schedule/detail/2529">Michael Koziarski</a> and <a href="http://en.oreilly.com/rails2008/public/schedule/detail/2021">Ezra Zygmuntowicz</a> have to say about Rails performance and scaling. This is definitely a hot topic - the whole conference program is filled up with performance/scaling talks. Looks like we should have been presenting as well, but ok, next year :)</p>

<p>It will be good to see <a href="http://en.oreilly.com/rails2008/public/schedule/detail/4356">Charles Nutter</a> and <a href="http://en.oreilly.com/rails2008/public/schedule/detail/1256">Ola Bini</a> of JRuby fame once again. We've always sympathized JRuby guys and appreciated their work, with the hope of course to run our <a href="http://www.acunote.com">Acunote</a> on top of JRuby to get some performance boost for free ;). Let's see how close we are to the goal this time...</p>

<p>What's also interesting is that Microsoft is back with <a href="http://en.oreilly.com/rails2008/public/schedule/detail/2056">IronRuby</a>. We're intrigued whether John Lam and Jimmy Schementi hacked it enough to run Rails or not.</p>

<p>We're also eager to hear what Bob Walker and Avi Bryant baked up with <a href="http://en.oreilly.com/rails2008/public/schedule/detail/2056">MagLev Ruby VM</a> and how far Evan Phoenix and his team progressed with <a href="http://en.oreilly.com/rails2008/public/schedule/detail/4342">Rubinius</a>.</p>

<p>For sure we're not only interested in alternative Ruby implementations. Scott Barron and Chad Humphries prepared a promising talk about profiling applications with <a href="http://en.oreilly.com/rails2008/public/schedule/detail/1945">DTrace on OSX</a>. Apart from Linux desktops we do use some MacBook's for development and might benefit from being able to use DTrace. Yehuda Katz's <a href="http://en.oreilly.com/rails2008/public/schedule/detail/1883">DataMapper</a> and Adam Pisoni's <a href="http://en.oreilly.com/rails2008/public/schedule/detail/2022">Skynet - A Ruby Map/Reduce Framework</a> talks look exciting as well. </p>

<p>So, we hope to learn something new and have fun in Portland once again this year. See you at RailsConf!</p>
<xhtml:img xmlns:xhtml="http://www.w3.org/1999/xhtml" src="http://feeds.feedburner.com/~r/pluron/~4/300870434" height="1" width="1" /></div></content>


    <feedburner:origLink>http://blog.pluron.com/2008/05/things-we-look.html</feedburner:origLink></entry>
    <entry>
        <title>Acunote for Google Summer of Code Projects</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/276273178/acunote-for-goo.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/04/acunote-for-goo.html" thr:count="1" thr:updated="2008-04-23T20:08:20-07:00" />
        <id>tag:typepad.com,2003:post-48895568</id>
        <published>2008-04-23T09:37:56-07:00</published>
        <updated>2008-04-23T20:08:21-07:00</updated>
        <summary>We in Pluron are great believers in open source. We develop and deploy with open source tools on open source platforms and we were always keen to give something back to the community. We've been [sponsoring KDE developer](http://adymo.blogspot.com/2006/06/my-job-is-my-passion-or-kdevelop.html) for two...</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        <category scheme="http://www.sixapart.com/ns/types#category" term="Acunote" />
        
        
<content type="xhtml" xml:lang="en-US" xml:base="http://blog.pluron.com/"><div xmlns="http://www.w3.org/1999/xhtml"><p>We in Pluron are great believers in open source. We develop and deploy with open source tools on open source platforms and we were always keen to give something back to the community. We've been <a href="http://adymo.blogspot.com/2006/06/my-job-is-my-passion-or-kdevelop.html">sponsoring KDE developer</a> for two years, we've released several parts of our product - <a href="http://www.acunote.com/open-source/javascript-keyboard-shortcuts">Acunote Shortcuts</a>, <a href="http://mediacloth.rubyforge.org">Mediacloth</a> and <a href="http://code.google.com/p/activerecpp/">ActiveReC++</a> under open source MIT license. But of course that's not everything we did.</p>

<p>We made Acunote <a href="http://www.acunote.com/open-source/acunote-for-open-source">free</a> for open source projects. Starting with summer 2007 we also offered Acunote access for Google Summer of Code program participants. </p>

<p>Google is running <a href="http://code.google.com/soc">Summer of Code program</a> for the fourth year now. Students who participate in this program write open source code but have their own designated projects with a deadline and a mentor assigned. The mentor needs to keep track of student's progress and has to review his code. And this is when Acunote becomes useful for both mentors and students because of its strong task management and <a href="http://www.acunote.com/tour/code_inspection">code review</a> capabilities.</p>

<p>Last year <a href="http://www.acunote.com/open-source/summer-of-code-projects">14 GSoC projects</a> used Acunote and we got some very positive feedback. This year we of course continue offering our lightweight and cool software project management tool for GSoC'ers. </p>

<p>So, if you are a student working on Summer of Code project or a mentor keeping an eye on such project, 
take look at our <a href="http://www.acunote.com/open-source/summer-of-code-projects">Acunote for GSoC HOWTO</a> page to learn how you can use it and <a href="http://www.acunote.com/open-source/summer-of-code-signup">signup for free</a>!</p>
<xhtml:img xmlns:xhtml="http://www.w3.org/1999/xhtml" src="http://feeds.feedburner.com/~r/pluron/~4/276273178" height="1" width="1" /></div></content>


    <feedburner:origLink>http://blog.pluron.com/2008/04/acunote-for-goo.html</feedburner:origLink></entry>
    <entry>
        <title>Pluron Rails Optimization Performance @ UA Web</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/257796145/pluron-rails-op.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/03/pluron-rails-op.html" thr:count="1" thr:updated="2008-04-25T00:21:45-07:00" />
        <id>tag:typepad.com,2003:post-47476494</id>
        <published>2008-03-25T10:38:08-07:00</published>
        <updated>2008-04-25T00:21:46-07:00</updated>
        <summary>Hi there. I will be giving a presentation on our Rails performance optimization work @ UA Web conference this Friday at President Hotel, Kiev, Ukraine . If you are a reader, please come by and say 'Hi.'</summary>
        <author>
            <name>Serge Smetana</name>
        </author>
        
        
<content type="xhtml" xml:lang="en-US" xml:base="http://blog.pluron.com/"><div xmlns="http://www.w3.org/1999/xhtml"><p>Hi there. I will be giving a presentation on our Rails performance optimization work @ <a href="http://uaweb.in.ua/news/4702.html">UA Web</a> conference this Friday  at <a href="http://uaweb.in.ua/delegates/3495.html">President Hotel</a>, Kiev, Ukraine .  If you are a reader, please come by and say 'Hi.'</p>
<xhtml:img xmlns:xhtml="http://www.w3.org/1999/xhtml" src="http://feeds.feedburner.com/~r/pluron/~4/257796145" height="1" width="1" /></div></content>


    <feedburner:origLink>http://blog.pluron.com/2008/03/pluron-rails-op.html</feedburner:origLink></entry>
    <entry>
        <title>Make Rails Associations Faster by Optimizing Named Blocks and String Callbacks</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/234541951/rails-faster-as.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/02/rails-faster-as.html" thr:count="16" thr:updated="2008-08-11T13:31:42-07:00" />
        <id>tag:typepad.com,2003:post-45571736</id>
        <published>2008-02-13T12:01:07-08:00</published>
        <updated>2008-08-11T13:31:42-07:00</updated>
        <summary>In our [previous](http://blog.pluron.com/2008/01/ruby-on-rails-i.html) [articles](http://blog.pluron.com/2008/01/guerrillas-way.html) we described how Rails spends much of its time garbage collecting, and that significant speedup can be achieved by [memory profiling](http://blog.pluron.com/2008/02/memory-profilin.html) and fixing memory allocation hotspots. In this article, we'll describe couple more such hotposts dealing...</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        <category scheme="http://www.sixapart.com/ns/types#category" term="Rails Performance" />
        
        
<content type="xhtml" xml:lang="en-US" xml:base="http://blog.pluron.com/"><div xmlns="http://www.w3.org/1999/xhtml"><p>In our <a href="http://blog.pluron.com/2008/01/ruby-on-rails-i.html">previous</a>
<a href="http://blog.pluron.com/2008/01/guerrillas-way.html">articles</a> we
described how Rails spends much of its time garbage collecting, and
that significant speedup can be achieved by <a href="http://blog.pluron.com/2008/02/memory-profilin.html">memory
profiling</a> and
fixing memory allocation hotspots.  In this article, we'll describe
couple more such hotposts dealing with named block parameters and
associations, and provide the patches.</p>

<h2>Named Block Parameters Considered Harmful (for Performance)</h2>

<p>We already <a href="http://blog.pluron.com/2008/01/ruby-on-rails-i.html#patches">wrote</a> that passing a block to a method of <code>ActiveRecord::Associations::HasManyAssociation</code> instance and its friends chews up the memory. For example, a single call to <code>association.select { |record| record.new_record? }</code> can allocate up to 10K of memory depending on the association size. A brief look at <a href="http://dev.rubyonrails.org/browser/tags/rel_2-0-2/activerecord/lib/active_record/associations">associations source</a> reveals that Rails itself has similar code in many places.</p>

<p>Each association is a proxy to the actual array of associated object(s). It seems like method_missing is a good way to implement proxy pattern in Ruby and indeed that's what Rails does. The proxy contains an array of associated objects and sends all missing methods in the proxy into that array. If we simplify the Rails code, we'll see something like this:</p>

<pre><code>class Association
    def method_missing(method, *args, &amp;block)
        @array.send(method, *args, &amp;block)
    end
end
</code></pre>

<p>At first, we couldn't understand why this would be slow, but after some digging we got it.  Each named <code>&amp;block</code> parameter requires extra processing. Ruby creates a <code>Proc</code> object that represents the block passed and adds a <code>Binding</code> object with the local execution context to that <code>Proc</code>. In an empty Ruby script without any variables defined binding will be around 400 bytes. In actual Rails application bindings may grow up to 10K in size. Now imagine you're doing something with AR object and its association in a loop 100 times. Bah! 1 megabyte of memory is gone.</p>

<p>Each Ruby block is a closure, and it captures its complete environment at the time of creation.  Ola Bini has a great <a href="http://ola-bini.blogspot.com/2007/12/ruby-closures-and-memory-usage.html">article</a> on this.  So is all hope lost?  No -- turns out that MRI has different implementations for named and anonymous block parameters.  When calling a function which takes anonymous block, it simply stores a reference to the caller's stack frame.  It's OK to do that since the callee is guaranteed to exit before caller's stack frame is popped.  When calling a function that takes a named block MRI assumes that this block may be long-lived and clones the environment right there.  So anonymous block parameters are much more efficient than named block parameters.  Also see related <a href="http://www.ruby-forum.com/topic/71221">discussion</a> on Ruby Forum.</p>

<p>The optimization to Rails Association is simple - just pass a new block and yield the old one inside:</p>

<pre><code>class Association
    def method_missing(method, *args)
        @array.send(method, *args) { |*block_args| yield(*block_args) if block_given? }
    end
end
</code></pre>

<p>This not only saves memory, but runs faster. I've benchmarked that on <a href="http://www.acunote.com">Acunote</a> copying 120 objects (each with 6 associations) using ActiveRecord.</p>

<p>With named block parameters:</p>

<pre><code>Benchmark Copy 120
memory: 97527K total in 1698240 allocations, GC calls: 13, GC time: 977 msec
time: 3.25 ± 0.05
</code></pre>

<p>With yields:</p>

<pre><code>Benchmark Copy 120
memory: 92670K total in 1636677 allocations, GC calls: 12, GC time: 901 msec
time: 3.15 ± 0.05
</code></pre>

<p>As the result, 5 megabytes of memory and 100msec saved for good.</p>

<h4>That's Cool! Where's The Patch?</h4>

<ul>
<li><a href="http://pluron.typepad.com/pluron/patches/no_block_args_in_associations.patch">Patch for Rails 1.2</a></li>
<li><p><a href="http://dev.rubyonrails.org/ticket/11109">Patch for Rails 2 (trunk)</a></p>

<ul>
<li>Patch accepted and committed into <a href="http://dev.rubyonrails.org/changeset/8865">trunk</a> and <a href="http://dev.rubyonrails.org/changeset/8866">2.0-stable branch</a> by <a href="http://weblog.techno-weenie.net/">Rick Olson</a></li>
</ul></li>
<li><p>Fix your code and remove <code>&amp;block</code>'s where you can</p></li>
</ul>

<h2>String Callbacks Considered Harmful (for Performance)</h2>

<p>This one is even more interesting. Rails allows for string callbacks in <code>before_save</code>, <code>after_save</code>, <code>before_destroy</code> and so on in ActiveRecord models. Each such callback is a string that is evaluated in the context of AR object. Let me cite Rails <a href="http://dev.rubyonrails.org/browser/tags/rel_2-0-2/activerecord/lib/active_record/associations">callbacks.rb</a> source here:</p>

<pre><code>...
def callback(method)
    notify(method)

    callbacks_for(method).each do |callback|
        result = case callback
            when Symbol
                self.send(callback)
            when String
                eval(callback, binding)
            when Proc, Method
                callback.call(self)
            else
            ...
</code></pre>

<p>You see, to evaluate the string we need to get the binding. And as we all remember from our named block parameter discussion, the binding takes memory.  Even when you don't use string callbacks yourself, Rails associations automatically create them for you.</p>

<p>For example, <code>has_many</code> will define 4 string callbacks. You'll get <code>before_save</code>, <code>after_create</code> and <code>after_update</code> to assure that new associated records are saved when its parent record is saved; and also you'll get one for <code>before_destroy</code> that destroys dependent objects or nullifies their foreign keys.</p>

<p>Rewriting string callbacks into symbol callbacks gives a tangible performance boost. I did that change and benchmarked Acunote again.</p>

<p>With string callbacks in associations:</p>

<pre><code>    Benchmark Copy 120
    memory: 92670K total in 1636677 allocations, GC calls: 12, GC time: 901 msec
    time: 3.15 ± 0.05
</code></pre>

<p>With symbol callbacks in associations:</p>

<pre><code>    Benchmark Copy 120
    memory: 39108K total in 944764 allocations, GC calls: 6, GC time: 479 msec
    time: 2.45 ± 0.05
</code></pre>

<p>Whoa! Rewriting string callbacks to symbol callbacks saved <b>52 megabytes</b> and gave <b>0.7 sec</b> speedup. Nice!</p>

<h4>That's Cool! Where The Patch?</h4>

<ul>
<li><a href="http://pluron.typepad.com/pluron/patches/no_string_callbacks_in_associations.patch">Patch for Rails 1.2</a></li>
<li><a href="http://dev.rubyonrails.org/ticket/11108">Patch for Rails 2 (trunk)</a>
<ul>
<li>Patch accepted and committed into <a href="http://dev.rubyonrails.org/changeset/8867">trunk</a> by <a href="http://weblog.techno-weenie.net/">Rick Olson</a></li>
</ul></li>
<li>Fix your code and stop using string callbacks</li>
</ul>
<xhtml:img xmlns:xhtml="http://www.w3.org/1999/xhtml" src="http://feeds.feedburner.com/~r/pluron/~4/234541951" height="1" width="1" /></div></content>


    <feedburner:origLink>http://blog.pluron.com/2008/02/rails-faster-as.html</feedburner:origLink></entry>
    <entry>
        <title>Make Your Ruby/Rails App Fast: Performance And Memory Profiling Using ruby-prof and KCachegrind</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/230525759/memory-profilin.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/02/memory-profilin.html" thr:count="5" thr:updated="2008-08-31T20:21:21-07:00" />
        <id>tag:typepad.com,2003:post-45234688</id>
        <published>2008-02-06T13:07:27-08:00</published>
        <updated>2008-08-31T20:21:22-07:00</updated>
        <summary>## Why Profiling and What to Profile? ## Last week we showed how we [sped up Acunote](http://blog.pluron.com/2008/01/ruby-on-rails-i.html) (our [agile project management](http://www.acunote.com) application) using memory profiling. That was the fish -- you can apply patches from that article and likely get...</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        <category scheme="http://www.sixapart.com/ns/types#category" term="Rails Performance" />
        
        
<content type="xhtml" xml:lang="en-US" xml:base="http://blog.pluron.com/"><div xmlns="http://www.w3.org/1999/xhtml"><h2>Why Profiling and What to Profile?</h2>

<p>Last week we showed how we <a href="http://blog.pluron.com/2008/01/ruby-on-rails-i.html">sped up Acunote</a> (our <a href="http://www.acunote.com">agile project management</a> application) using memory profiling.  That was the fish -- you can apply patches from that article and likely get nice boost for your app (we got 5x).  Today we give you the net and show how to identify performance and memory usage bottlenecks in <strong>your</strong> Ruby/Rails application.</p>

<p>Profiling performance and memory separately dramatically simplifies optimizing ruby code, and turns it into a deterministic profile/fix/go-faster/repeat loop, rather than (profile or guess)/fix/(get disappointed)/(get discouraged) loop it was before.  Read on to learn how.</p>

<h2>Preparations And Tools</h2>

<p>First, get <a href="ftp://ftp.ruby-lang.org/pub/ruby/1.8/ruby-1.8.6-p111.tar.gz">Ruby 1.8.6 sources</a>, <a href="http://rubyforge.org/tracker/download.php/1814/7062/17676/3291/ruby186gc.patch">patch</a> them, compile and install. Ruby 1.8.5 will work the same patch too.  Vanilla Ruby GC doesn't give us enough information, hence the need for a <a href="http://rubyforge.org/tracker/download.php/1814/7062/17676/3291/ruby186gc.patch">patch</a> (composed from <a href="http://rubyforge.org/tracker/index.php?func=detail&amp;aid=11497&amp;group_id=426&amp;atid=1700">Sylvain Joyeux's memory allocations patch</a>, <a href="http://railsbench.rubyforge.org/svn/trunk/railsbench/ruby186gc.patch">Stefan Kaes' Railsbench GC patch</a>, and my own memory counter; the patch applies to both Ruby 1.8.5 and 1.8.6). It's a good idea to install patched Ruby into its own prefix (say, <code>configure --prefix=~/bin/ruby</code>) and to adjust the $PATH every time you need to profile.</p>

<p>Second, install the recently released ruby-prof 0.6.0. <code>gem install ruby-prof</code> or <code>gem update ruby-prof</code> should do the job. ruby-prof 0.5.2 does not have the memory profiler we'll need, but you can <a href="http://rubyforge.org/tracker/download.php/1814/7062/17676/3290/allocated_memory_size_measurement.patch">patch it</a> if you really need to. It is important to have and use patched ruby before you start installing ruby-prof gem, otherwise installed gem will not have support for memory profiling compiled in.</p>

<h2>Measure/Benchmark</h2>

<p>Before profiling you need to measure the current state. Forget about Rails logger and request time recorded there. You need information about:</p>

<ul>
<li>request time;</li>
<li>size of memory allocated during the request;</li>
<li>number of objects allocated during the request;</li>
<li>number of GC collections;</li>
<li>time spent in GC.</li>
</ul>

<p>To get request time we'll use <code>Benchmark.realtime {}</code>  The get memory use and GC stats we'll use this helper:</p>

<pre><code>#Executes block and collects GC statistics during the block execution.
#Collected stats are printed to stdout (or to the file set in $RUBY_GC_DATA_FILE env var):
# - allocated memory size (in KB) during block execution
# - number of memory allocations during block execution
# - number of GC collections during block execution
# - time (in milliseconds ) spent in GC
#
#Description string appears in stdout before statistics
#Options are
# - :disable_gc =&gt; true    - disables GC during execution
# - :show_gc_dump =&gt; true  - shows GC heap dump after statistics
def gc_statistics(description = "", options = {})
    #do nothing if we don't have patched Ruby GC
    yield and return unless GC.respond_to? :enable_stats

    GC.enable_stats || GC.clear_stats
    GC.disable if options[:disable_gc]

    yield

    stat_string = description + ": "
    stat_string += "allocated: #{GC.allocated_size/1024}K total in #{GC.num_allocations} allocations, "
    stat_string += "GC calls: #{GC.collections}, "
    stat_string += "GC time: #{GC.time / 1000} msec"

    GC.log stat_string
    GC.dump if options[:show_gc_dump]

    GC.enable if options[:disable_gc]
    GC.disable_stats
end
</code></pre>

<p>I personally find it Zen to create a special kind of integration tests for benchmarks (let's call them "performance tests").</p>

<p>Using gc_statistics helper a performance test can look like this:</p>

<pre><code>class PostsPerformanceTest &lt; ActionController::IntegrationTest
    def test_index
        puts "posts/index:"
        benchmark_time :get, 'posts/index'
        benchmark_memory :get, 'posts/index'
    end

    def benchmark_time(method, url)
        measured_times = []
        10.times { measured_times &lt;&lt; Benchmark.realtime { send(method, url) } }
        puts "time: #{mean(measured_times).to_02f} ± #{deviation(measured_times).to_02f}\n"
    end

    def benchmark_memory(method, url)
        gc_statistics("memory: ") { send(:method, url) }
    end

    def mean(values)
        values.sum / values.length
    end
    def deviation(values)
        m = mean(values)
        Math.sqrt(values.inject(0){|sum, a| sum + (a - m)**2} / values.length)
    end
end
</code></pre>

<p>Sample output from such test will look like:</p>

<pre><code>posts/index:
time: 3.50 ± 0.01
memory: allocated: 150246K total in 1650700 allocations, GC calls: 19, GC time: 1500 msec
</code></pre>

<p>The results as in example output above suggest optimizing memory first because it's possible to save more than a second by producing less garbage and doing less garbage collections (19 is too much). My experience in optimizing Rails apps tells that normally you should aim at 1-2 GC calls per request and ideally you can get no GC collections at all. Of course, some long requests may inevitably use more memory but the rule of thumb is: <em>less GC collections is better</em>.</p>

<h2><a name="profile" />How to Profile</h2>

<p>Profiling with ruby-prof is very similar to measurements we've seen above. Integration tests again become the Zen way to profile (let's call them "profiling tests").</p>

<p>Profiling test should:</p>

<ul>
<li>run ruby-prof to generate processing time profile;</li>
<li>run ruby-prof to generate memory profile;</li>
<li>output profiling results in a suitable format (preferably, calltree).</li>
</ul>

<p>For example, profiling test can look like this:</p>

<pre><code>require 'ruby-prof'

class PostsController
    alias :index_orig, :index
    def index
        RubyProf.start
        index_orig
        result = RubyProf.stop

        measure_names = { RubyProf::MEMORY =&gt; 'memory', RubyProf::PROCESS_TIME =&gt; 'time' }

        printer = RubyProf::CallTreePrinter.new(result)
        printer.print(File.open("callgrind.out.posts_index_#{measure_names[RubyProf::measure_mode]}", 'w'))
    end
end

class PostsProfilingTest &lt; ActionController::IntegrationTest
    def setup
        GC.disable
    end
    def teardown
        GC.enable
    end

    def test_index
        profile :get, 'posts/index'
    end

    def profile(method, url)
        RubyProf.measurement_mode = RubyProf::PROCESS_TIME
        send(method, url)
        RubyProf.measurement_mode = RubyProf::MEMORY
        send(method, url)
    end
end
</code></pre>

<p>Note that we do 2 separate profiler runs, one for PROCESS_TIME and one for MEMORY.  That's because the profiler only supports measuring one thing at a time.</p>

<p>There are a few more things to note.  The code disables GC for the time of request. Otherwise ruby-prof attributes full time cost of garbage collection to the method where GC gets triggered, not the methods that allocate the memory.  For profiling we need deterministic behavior without GC.  See <a href="http://blog.pluron.com/2008/01/ruby-on-rails-i.html">original article</a> for more info on this.</p>

<p>Second, the test records profiler information only for controller action. There's no point in profiling Rails integration testing framework and GCI dispatcher when we need to profile only our application.</p>

<p>Finally, and most importantly, the code outputs results in the calltree format for use with excellent <a href="http://kcachegrind.sourceforge.net/">KCachegrind</a> profiler data visualization tool by Josef Weidendorfer.</p>

<h2>Using KCachegrind</h2>

<p>With KCachegrind you get all the goodies:</p>

<ul>
<li>the list of methods sortable by <em>both</em> their total time and self time;</li>
<li>call graph visualization;</li>
<li>easy access to callers and callee's of any given function;</li>
<li>cycle detection in the code;</li>
<li>profiler-annotated source code listings;</li>
<li>more stuff like search, relative and percentage cost calculations, etc.</li>
</ul>

<p>In short, with KCachegrind it is much easier to understand profiler output compared with using plain text and HTML formatted ruby-prof results. I guess the example screenshot below will be the best proof of that.<br />
<a href="http://pluron.typepad.com/.shared/image.html?/pluron/images/kcachegrind.png" onclick="window.open(this.href, '_blank', 'width=1019,height=770,scrollbars=no,resizable=no,toolbar=no,directories=no,location=no,menubar=no,status=no,left=0,top=0'); return false"><img alt="Kcachegrind" title="Kcachegrind" src="http://blog.pluron.com/images/2008/02/06/kcachegrind.png" width="600" height="453" border="0" /></a></p>

<p><small>KCachegrind is a part of KDE kdesdk distribution. Linux'ers should not have any troubles installing it. On MacOS X you can install KCachegrind from either <a href="http://www.macports.org/">MacPorts</a> with <code>port install kcachegrind</code> or from <a href="www.finkproject.org/">Fink</a>. In both cases <a href="http://developer.apple.com/opensource/tools/X11.html">Apple X11</a> is necessary. Those who still are on Windows may try installing KCachegrind from <a href="http://kde-cygwin.sourceforge.net/">KDE-Cygwin</a> or resort to <a href="http://sourceforge.net/projects/wincachegrind/">WinCacheGrind</a> or even to HTML output.</small></p>

<p>By this point you should get all the data and only a few simple things left to do.  KCachegrind's function profile sidebar will show you which methods took long to execute and which methods ate the memory. Call stack sidebar and call tree will show you where those methods are called from. Source listing will help you to traverse the call tree and locate hotspots.  This is all you need to understand where you app is slow and where it eats lots of memory.</p>

<p>Next step is to fix these problems.</p>

<h2><a name="optimize" />How to Optimize</h2>

<p>Unlike profiling, optimization is not deterministic and there's no universal recipe on how to fix the slowdowns.  There're some common tricks and although they are off topic here, I'll give you some most important ones:</p>

<ul>
<li>look for <code>Kernel#clone</code> in profiler and fix your code - never clone objects;</li>
<li>do not use <code>ActiveRecord::Base::attributes</code> method, it clones attributes;</li>
<li>don't use named block parameters when you can, replace <code>def myfun(&amp;block)</code> declarations with <code>def myfun</code>;</li>
<li>avoid stuff with O(n<sup>2</sup>) performance like <code>acts_as_list</code> and be careful with <code>acts_as_tree</code> as well;</li>
<li>execute fewer queries, especially with ActiveRecord;</li>
<li>don't use <code>link_to_function</code>, <code>text_field_tag</code>, <code>check_box_tag</code> and <code>image_tag</code> if you can;</li>
<li>preload objects with <code>:include =&gt; ''</code> find parameter where possible;</li>
<li>don't render too many partials.</li>
</ul>

<p>Complete explanation of the hints is well worth the separate blog post, but that's for the future.</p>

<h2>Optimize Today!</h2>

<p>I hope you'll enjoy profiling and optimizing your application like I did. This is a greatly rewarding work, in some cases I got 5x improvements using the techniques described above. Some of the findings (including Ruby and Rails optimizations) are described in two previous blog posts:<br />
<a href="http://blog.pluron.com/2008/01/guerrillas-way.html">Guerrilla's Guide to Optimizing Rails Applications</a><br />
<a href="http://blog.pluron.com/2008/01/ruby-on-rails-i.html">Garbage Collection is Why Ruby on Rails is Slow: Patches to Improve Performance 5x; Memory Profiling</a></p>

<p>In any case, if you have your own suggestions or improvements to the method, optimization tricks, please share them. I'll post them here.</p>
<xhtml:img xmlns:xhtml="http://www.w3.org/1999/xhtml" src="http://feeds.feedburner.com/~r/pluron/~4/230525759" height="1" width="1" /></div></content>


    <feedburner:origLink>http://blog.pluron.com/2008/02/memory-profilin.html</feedburner:origLink></entry>
    <entry>
        <title>Guerrilla's Guide to Optimizing Rails Applications</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/226925499/guerrillas-way.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/01/guerrillas-way.html" thr:count="15" thr:updated="2008-12-08T23:10:58-08:00" />
        <id>tag:typepad.com,2003:post-44967210</id>
        <published>2008-01-31T17:35:33-08:00</published>
        <updated>2008-12-08T23:10:58-08:00</updated>
        <summary>## The Battle For Performance ## Rails is slow. Your rails application which does fairy simple database operations will be born slow and will eventually become slower and slower while still not doing anything fancy. That's like getting a new...</summary>
        <author>
            <name>Alexander Dymo</name>
        </author>
        <category scheme="http://www.sixapart.com/ns/types#category" term="Rails Performance" />
        
        
<content type="html" xml:lang="en-US" xml:base="http://blog.pluron.com/">
&lt;div xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;h2&gt;The Battle For Performance&lt;/h2&gt;

&lt;p&gt;Rails is slow. Your rails application which does fairy simple database operations will be born slow and will eventually become slower and slower while still not doing anything fancy. That's like getting a new powerful locomotive (on Rails) together with a free bonus of overladen freight cars.&lt;/p&gt;

&lt;p&gt;Having said that, I can virtually hear the herd of voices screaming "dude, optimize your own application and don't blame Ruby and Rails for everything". Sure thing, our application isn't perfect and I do believe it can be optimized but you can't win the performance battle just by that.&lt;/p&gt;

&lt;p&gt;The winning tactics for this battle is guerrilla tactics. It turns out you can guerrilla-patch (aka monkey-patch) Ruby and Rails and easily get up to 3x speedup in some cases. We started doing that to our own application - &lt;a href="http://www.acunote.com"&gt;Acunote&lt;/a&gt; and got amazing results so far. Read on to find out how.&lt;/p&gt;

&lt;h2&gt;Ruby-Prof: The Guerrilla's Weapon&lt;/h2&gt;

&lt;p&gt;Acunote, our pet rails application, often need to copy a bunch of ActiveRecord (AR) objects. As any other project management tools, our application works with tasks organized into iterations (sprints). Sometimes you want to copy tasks from current iteration/sprint to the next iteration/sprint. And boy, that copy can become really slow. As an example, let's look at the performance and profiling data of one request to copy 120 tasks.&lt;/p&gt;

&lt;p&gt;Let's measure 3 things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the real time request takes in production environment;&lt;/li&gt;
&lt;li&gt;processing time profile information using the excellent &lt;a href="http://ruby-prof.rubyforge.org/"&gt;ruby-prof&lt;/a&gt; profiler by &lt;a href="http://cfis.savagexi.com"&gt;Charlie Savage&lt;/a&gt; and &lt;a href="http://blog.shugo.net/"&gt;Shugo Maeda&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;memory profile information gathered with patched ruby-prof (I took Sylvain Joyeux's memory allocations measurement mode patches and hacked together my own ruby-prof &lt;a href="http://rubyforge.org/tracker/index.php?func=detail&amp;amp;aid=17676&amp;amp;group_id=1814&amp;amp;atid=7062"&gt;memory size measurement mode&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, for "copy 120" request we get:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Request time (without profiler): 13.6 sec.

Time:
 Total: 16.78
 %self     total     self     wait    child    calls  name
 18.36      3.34     3.08     0.00     0.26    20766  Kernel#clone
  ...

Allocated Memory Size (in KB):
 Total: 1 001 730.00
 %self     total       self     wait    child    calls  name
 61.87  646795.00 619745.00     0.00 27049.00    20766  Kernel#clone
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;"WTF" politely describes my initial reaction when I first saw that. How on earth we can spend &lt;b&gt;17 seconds&lt;/b&gt; and consume &lt;b&gt;1&amp;nbsp;Gigabyte&lt;/b&gt; of memory by just copying &lt;b&gt;120&lt;/b&gt; ActiveRecord objects? Ok, ok, we not only copy them but store some more information to the database like task tags, copy events and so on. Therefore we end up saving actually 360 AR objects instead of 120. Also the memory profiler is inaccurate and usually shows a bit more memory than the process actually takes.&lt;/p&gt;

&lt;p&gt;Still, what is going on during those 17 seconds? Why do we need a gig of RAM? Gee, on the same machine I can compile the whole ruby interpreter in 57 seconds and the compiler will never take more than 130M...&lt;/p&gt;

&lt;p&gt;Heh, let's calm down and see what profiler says. The obvious suspect is &lt;code&gt;Kernel#clone&lt;/code&gt; method. The (stripped) call tree for it as reported by ruby-prof is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Task#save
...
ActiveRecord::Base#create_without_callbacks
ActiveRecord::Base#attributes_with_quotes
ActiveRecord::Base#attributes
ActiveRecord::Base#clone_attributes
ActiveRecord::Base#clone_attribute_value
Kernel#clone
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From &lt;a href="http://cfis.savagexi.com/articles/2007/07/18/making-rails-go-vroom"&gt;Charlie's blog&lt;/a&gt; we know that &lt;code&gt;AR::Base::attributes method&lt;/code&gt; is evil. It clones attributes before returning them and Charlie gave a wise advice to not use it. And indeed in your application is a good idea to call, for example, &lt;code&gt;task['foo']&lt;/code&gt; instead of &lt;code&gt;task.foo&lt;/code&gt; or &lt;code&gt;task.attributes['foo']&lt;/code&gt;. But here &lt;code&gt;AR::Base::create&lt;/code&gt; itself does the evil thing.&lt;/p&gt;

&lt;p&gt;Let me cite Rails code (from rails/activerecord/lib/activerecord/base.rb):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def update
    connection.update(
        "UPDATE #{self.class.table_name} " +
        "SET #{quoted_comma_pair_list(connection, attributes_with_quotes(false))} " +
        "WHERE #{self.class.primary_key} = #{quote_value(id)}",
        "#{self.class.name} Update"
    )
end

def create
    if self.id.nil? &amp;amp;&amp;amp; connection.prefetch_primary_key?(self.class.table_name)
        self.id = connection.next_sequence_value(self.class.sequence_name)
    end
    self.id = connection.insert(
        "INSERT INTO #{self.class.table_name} " +
        "(#{quoted_column_names.join(', ')}) " +
        "VALUES(#{attributes_with_quotes.values.join(', ')})",
        "#{self.class.name} Create",
        self.class.primary_key, self.id, self.class.sequence_name
    )
    @new_record = false
    id
end

def quoted_column_names(attributes = attributes_with_quotes)
    attributes.keys.collect do |column_name|
        self.class.connection.quote_column_name(column_name)
    end
end

def attributes_with_quotes(include_primary_key = true)
    attributes.inject({}) do |quoted, (name, value)|
        if column = column_for_attribute(name)
            quoted[name] = quote_value(value, column) unless !include_primary_key &amp;amp;&amp;amp; column.primary
        end
        quoted
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! &lt;code&gt;AR::create&lt;/code&gt; clones all attributes twice (first with &lt;code&gt;quoted_column_names&lt;/code&gt; and then with &lt;code&gt;attributes_with_quotes&lt;/code&gt;). &lt;code&gt;AR::update&lt;/code&gt; is a nicer guy, it clones attributes only once. For each of those 120 copied tasks we use &lt;code&gt;AR::create&lt;/code&gt; twice and &lt;code&gt;AR::update&lt;/code&gt; once. Therefore we call &lt;code&gt;clone_attributes&lt;/code&gt; not less than 120*2*2+120 = 600 times.&lt;/p&gt;

&lt;p&gt;Profiler says we lose 3 seconds and 650M memory because of that:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ActiveRecord::Base#clone_attributes:
Time:          3.21 sec
Memory:  650 301.00 K
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok. Time to employ our promised guerrilla tactics, but first let's talk about memory.&lt;/p&gt;

&lt;h2&gt;Lyrical Digression: Why Do We Care About Memory?&lt;/h2&gt;

&lt;p&gt;While guerrilla warriors take a nap before the battle, let's digress and look at why we measure the size of allocated memory. Sure thing, allocating literally tons of memory is bad. But we're using Ruby and Ruby has its own guerrilla warrior which strikes our application when it innocently eats its tasty memory.&lt;/p&gt;

&lt;p&gt;The name of our enemy is "Ruby Garbage Collector" and the cunning enemy it is. As ruby's gc.c source says and Why the Lucky Stiff &lt;a href="http://whytheluckystiff.net/articles/theFullyUpturnedBin.html"&gt;explains&lt;/a&gt;, ruby GC kicks in when you allocate more memory than is available on the heap and heap boundary is 8M. When we sequentially allocate 650 megabytes there's a chance that GC will be called 650/8=81 times. Each GC call accounts for approximately 70-80ms which in our case should add roundabout 5 seconds to the running time.&lt;/p&gt;

&lt;p&gt;Let's do some math... Kernel#clone itself takes 3 seconds and we expect garbage collection to take 5 more seconds. In total, 8 seconds are wasted because of cloning. See the trend? The more memory we allocate the worse our performance is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Here's the morale: "watch your memory". Large memory consumption costs you more than you'd otherwise think because of garbage collection.&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;Guerrilla patching AR::create and AR::update&lt;/h2&gt;

&lt;p&gt;Now it's time to employ our guerrilla tactics and fix ActiveRecord. It's easy to rewrite &lt;code&gt;attributes_with_quotes&lt;/code&gt; and avoid cloning the attributes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module ActiveRecord
    class Base
    private
        def attributes_with_quotes(include_primary_key = true)
            result = {}
            @attributes.each_key do |name|
                if column = column_for_attribute(name)
                    result[name] = quote_value(read_attribute(name), column) unless !include_primary_key &amp;amp;&amp;amp; column.primary
                end
            end
            result
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let's put that to environment.rb and see what we get:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Request time (without profiler): 6.7 sec.

Time:
 Total: 9.5
 %self     total     self     wait    child    calls  name
  4.84      0.69     0.46     0.00     0.23    24023  ActiveRecord::ConnectionAdapters::Quoting#quote
  ...
  2.22      0.52     0.18     0.00     0.34     2779  &amp;lt;Module::Benchmark&amp;gt;#realtime
  ...
  0.00      0.00     0.00     0.00     0.00        6  Kernel#clone
  ...

Allocated Memory Size (in KB):
 Total: 350 966.00
 %self     total       self     wait    child    calls  name
 34.31  125655.00 120420.00     0.00  5235.00     2779  &amp;lt;Module::Benchmark&amp;gt;#realtime
  ...
  0.00       0.00      0.00     0.00     0.00        6  Kernel#clone
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, much better: &lt;b&gt;650 megabytes of memory saved&lt;/b&gt; with that little monkey patch! We estimated that will save 8 seconds. Let's look:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Original request time:          13.6 sec
Request time after AR patch:     6.7 sec
Time saved:                      6.9 sec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It turns out our estimation was almost correct. &lt;b&gt;We indeed saved not only the time taken by &lt;code&gt;Kernel#clone&lt;/code&gt; but also the time spent by garbage collector and gained 2x speedup for free.&lt;/b&gt; Nice! Our guerrilla tactics clearly works and we can for sure do better than 2x.&lt;/p&gt;

&lt;h2&gt;Guerrilla-patching Benchmark.realtime&lt;/h2&gt;

&lt;p&gt;Next suspect, as seen from memory profile above, is &lt;code&gt;Benchmark#realtime&lt;/code&gt;. From time profiler the method doesn't look bad. We spend only 180 milliseconds in it but look at memory profiler! It 180ms our &lt;code&gt;Benchmark#realtime&lt;/code&gt; friend allocates &lt;b&gt;120 megabytes&lt;/b&gt; of memory. Guess what? Ruby garbage collector will be happy to kick our ass again at least 15 times and that estimates to about 1 second loss.&lt;/p&gt;

&lt;p&gt;Let's see what's wrong in benchmark.rb:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def measure(label = "")
    t0, r0 = Benchmark.times, Time.now
    yield
    t1, r1 = Benchmark.times, Time.now
    Benchmark::Tms.new(t1.utime  - t0.utime, t1.stime  - t0.stime,
        t1.cutime - t0.cutime, t1.cstime - t0.cstime, r1.to_f - r0.to_f, label)
end

def realtime(&amp;amp;blk)
    Benchmark::measure(&amp;amp;blk).real
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great, we calculate lots of useless information (like cpu time, user time, etc) in &lt;code&gt;Benchmark#measure&lt;/code&gt; and then just throw it away. Let's do better, simpler and more memory efficient:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module Benchmark
    def realtime
        r0 = Time.now
        yield
        r1 = Time.now
        r1.to_f - r0.to_f
    end
    module_function :realtime
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That's it. No extra object creation. And here's our income:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Request time (without profiler): 5.8 sec.

Time:
 Total: 8.63
 %self     total     self     wait    child    calls  name
  4.29      0.69     0.46     0.00     0.23    24023  ActiveRecord::ConnectionAdapters::Quoting#quote
  ...
  0.35      0.19     0.03     0.00     0.16     2779  &amp;lt;Module::Benchmark&amp;gt;#realtime
  ...

Allocated Memory Size (in KB):
 Total: 225 668.00
 %self     total       self     wait    child    calls  name
 43.78   98805.00  98805.00     0.00     0.00     5280  Kernel#binding
  0.00    1918.00      2.00     0.00  1916.00     2779  &amp;lt;Module::Benchmark&amp;gt;#realtime
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Whoa! &lt;b&gt;120 megabytes&lt;/b&gt; and &lt;b&gt;1 second&lt;/b&gt; were saved with 9-liner guerrilla patch. Nice, isn't it? Instead of original 13.6 sec our request now runs in 5.8 sec. That's more than 2x improvement already and we can do even better, but I'll leave that for the next blog.&lt;/p&gt;

&lt;h2&gt;When Guerrilla Tactics Help&lt;/h2&gt;

&lt;p&gt;Nothing with Ruby and Rails is wrong until you do things in the loop. For example, &lt;code&gt;Benchmark#realtime&lt;/code&gt; doesn't have any impact if all you do is save one AR object. You just allocate 25 extra objects that take 45 extra kilobytes. But you're doomed once you do that in a loop. Do the benchmark 200 times and you'll guaranteed the garbage collector will happily shoot you in the back.&lt;/p&gt;

&lt;p&gt;Also bear in mind that garbage collector should not be running while you profile your code. With GC you'll never get repeatable results because it will kick in at different times randomly increasing the time and memory consumption of your methods.&lt;/p&gt;

&lt;h2&gt;Make Your Application Fast: Optimize MEMORY&lt;/h2&gt;

&lt;p&gt;Let me reiterate, &lt;b&gt;by optimizing memory usage instead of (or in parallel with) processing time you can get significant performance improvement, and guerrilla patching memory-inefficient bits is the right way to make Ruby and Rails faster&lt;/b&gt; I think we're on the right track here. Memory is what we need to optimize. Memory is what wasn't optimized before. And you've just seen what we can get by optimizing memory.&lt;/p&gt;

&lt;p&gt;We (Acunote devs) will continue the memory profiling and will blog as soon as we get new results. &lt;a href="http://blog.pluron.com/2008/01/ruby-on-rails-i.html"&gt;Our previous blog post&lt;/a&gt; briefly summarize our current results, be sure to read it if you haven't done that yet. Meanwhile, don't wait for us, grab ruby-prof, &lt;a href="http://rubyforge.org/tracker/index.php?func=detail&amp;amp;aid=17676&amp;amp;group_id=1814&amp;amp;atid=7062"&gt;my memory profiler patches&lt;/a&gt; and dig by yourself ;) I bet you'll find more big memory eaters and when you do so, please drop us a note. Let's collect our guerrilla patches and then file them upstream.&lt;/p&gt;
&lt;/div&gt;
&lt;img src="http://feeds.feedburner.com/~r/pluron/~4/226925499" height="1" width="1"/&gt;</content>


    <feedburner:origLink>http://blog.pluron.com/2008/01/guerrillas-way.html</feedburner:origLink></entry>
    <entry>
        <title>Garbage Collection is Why Ruby on Rails is Slow: Patches to Improve Performance 5x; Memory Profiling</title>
        <link rel="alternate" type="text/html" href="http://feeds.feedburner.com/~r/pluron/~3/226896883/ruby-on-rails-i.html" />
        <link rel="replies" type="text/html" href="http://blog.pluron.com/2008/01/ruby-on-rails-i.html" thr:count="33" thr:updated="2008-09-18T22:27:20-07:00" />
        <id>tag:typepad.com,2003:post-44962968</id>
        <published>2008-01-31T16:07:03-08:00</published>
        <updated>2008-09-18T22:27:20-07:00</updated>
        <summary>* __The News__: Ruby on Rails performance is dominated by garbage collection. We present a set of patches to greatly improve Rails performance and show how to profile memory usage to get further performance gains. * __What's at Stake__: Rails...</summary>
        <author>
            <name>Gleb Arshinov</name>
        </author>
        <category scheme="http://www.sixapart.com/ns/types#category" term="Rails Performance" />
        
        
<content type="html" xml:lang="en-US" xml:base="http://blog.pluron.com/">
&lt;div xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The News&lt;/strong&gt;: Ruby on Rails performance is dominated by garbage
      collection.  We present a set of patches to greatly improve
      Rails performance and show how to profile memory usage to
      get further performance gains.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What's at Stake&lt;/strong&gt;: 
      Rails is slow for many uses and did not lend itself well to
      optimization.  Significant performance gains could only be
      achieved at application level at large development cost.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Upside&lt;/strong&gt;: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;5x potential performance gains;&lt;/li&gt;
&lt;li&gt;easy way to identify whether GC is a bottleneck;&lt;/li&gt;
&lt;li&gt;deterministic process to fix memory bottlenecks;&lt;/li&gt;
&lt;li&gt;set of canned patches to solve the biggest problems;&lt;/li&gt;
&lt;li&gt;you can help&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;I don't have time, make my app 5 times faster!&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Apply the &lt;a href="#patches"&gt;monkey patches&lt;/a&gt; below.  Enjoy.&lt;/li&gt;
&lt;li&gt;Time your app with garbage collection disabled to figure out
how much more performance you are leaving on the table.  Enjoy.&lt;/li&gt;
&lt;li&gt;Come back for more patches.  Enjoy.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;What's going on here?&lt;/h2&gt;

&lt;p&gt;Ruby runtime uses garbage collection.  Your code allocates memory as
it runs.  From time to time garbage collector kicks in, halts the
whole system, and cleans up no-longer-referenced memory using
mark-and-sweep algorithm.&lt;/p&gt;

&lt;p&gt;GC gets triggered by multiple conditions. The one that matters the
most is 8M trigger.  Every time you allocate 8M of memory GC runs.
Complex Rails request can allocate hundreds or even thousands of
megabytes of memory, making &lt;strong&gt;GC runs dozens of times&lt;/strong&gt;.  &lt;strong&gt;Each GC
pass takes 50-150ms&lt;/strong&gt;.  You do the math.&lt;/p&gt;

&lt;p&gt;It's possible to patch ruby interpreter, increase the triggers and
reduce frequency of garbage collection at the cost of additional
memory use.  This helps, but does not resolve the problem.  If there
is more garbage, each GC run takes longer.  We'll devote a separate
post to this later.&lt;/p&gt;

&lt;h2&gt;But, I am running ruby-prof already, you ignorant fool!?&lt;/h2&gt;

&lt;p&gt;And so are we.  It does not really help:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ruby-prof attributes full cost of garbage collection to the
method where GC gets triggered, not the methods that allocate the
memory&lt;/strong&gt;.  That's like blaming the last straw for breaking the
camel's back.&lt;/li&gt;
&lt;li&gt;ruby-prof does not show that garbage collection took place and how
much time it took.  All you can tell is that some method took a long
time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you go by the these result, and remove the straw that's
breaking the camel's back his load does not get much lighter.&lt;/p&gt;

&lt;p&gt;Statistics being on your side, things are not entirely hopeless.  GC
gets triggered within malloc, so methods doing a lot allocations are
also likely to trigger GC.  Further, simply allocating memory is
relatively expensive, and that will also show up in profiler output.&lt;/p&gt;

&lt;p&gt;You might get lucky, optimize ruby-prof hotspot and get better
performance, but more often than not you will fail.  The correlation
is just too weak.  We believe this is exactly why Rails resisted
performance optimization.  Up till now.&lt;/p&gt;

&lt;h2&gt;Profiling memory allocations&lt;/h2&gt;

&lt;p&gt;Ruby-prof is almost the right tool for memory profiling. "Almost" is
because the free cheese is only found in the mousetrap. You'll have to
do some work first.&lt;/p&gt;

&lt;p&gt;You need to build patched ruby (&lt;a href="http://rubyforge.org/tracker/download.php/1814/7062/17676/3291/ruby186gc.patch"&gt;patch
here&lt;/a&gt;)
and latest ruby-prof (&lt;a href="http://rubyforge.org/tracker/download.php/1814/7062/17676/3290/allocated_memory_size_measurement.patch"&gt;patch
here&lt;/a&gt;). With
both tools patched, set &lt;code&gt;RubyProf.measure_mode = RubyProf::MEMORY&lt;/code&gt;
before running the profiler.&lt;/p&gt;

&lt;p&gt;Make sure to turn off GC when profiling for pure performance. You'll
get get much more representative results.&lt;/p&gt;

&lt;p&gt;The detailed HOWTO and description on the process is in our &lt;a href="http://blog.pluron.com/2008/01/guerrillas-way.html"&gt;next blog post&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Will it help me?&lt;/h2&gt;

&lt;p&gt;In general your code will benefit most if you:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create or update a lot of rows using ActiveRecord&lt;/li&gt;
&lt;li&gt;Run large number of SQL statements of any kind using ActiveRecord,
e.g. load many AR object through separate #find calls&lt;/li&gt;
&lt;li&gt;Use ActiveView helpers, especially in a loop, to generate complex
HTML&lt;/li&gt;
&lt;li&gt;Use has_many AR association&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It's easy to tell for sure if you have performance tests.  All that
"performance test" means is that you can run a single request and time
how long it takes.&lt;/p&gt;

&lt;p&gt;Just run the same test as usual, and then with GC disabled and compare
the results.  Most code will run much faster with GC disabled.
E.g. for &lt;a href="http://www.acunote.com"&gt;Acunote&lt;/a&gt; we test how long it takes
to copy 120 tasks from one sprint from another.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Before optimizations with GC:   14 sec
Before optimizations w/out GC:   6 sec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can't run ruby without GC in production.  It will rapidly run out
of memory and crash.  You can, however, apply optimization, produce
less garbage and get your code be even faster than original benchmark
with GC turned off!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;After optimizations with GC:     3 sec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code that allocates little memory, but is algorithmically complex
and is slow because of that, will see little improvement.  For example
Acunote's &lt;a href="http://www.acunote.com/tour/burndown"&gt;burndown&lt;/a&gt; and sprint
completion date calculations fall squarely into this category and did
not benefit.  These aside, Acunote performance was dominated by the
cost of memory allocation.&lt;/p&gt;

&lt;p&gt;&lt;a name="patches"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Give me the patches!&lt;/h2&gt;

&lt;table border="1" cellpadding="2" cellspacing="0"&gt;

&lt;tr&gt;

 &lt;th width="50%"&gt;Problem&lt;/th&gt;
 &lt;th width="50%"&gt;Patch&lt;/th&gt;

&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

&lt;code&gt;ActiveRecord::Base#create&lt;/code&gt; calls &lt;code&gt;attributes_with_quotes&lt;/code&gt; twice, &lt;code&gt;ActiveRecord::Base#update&lt;/code&gt; once. &lt;code&gt;#attributes_with_quotes&lt;/code&gt; calls &lt;code&gt;#attributes&lt;/code&gt;, which clones all attribute values. None of these clones are necessary.
&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
When copying 120 tasks in Acunote this costs 650M. Patch improves performance from 14s to 6s.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
Helps when you do a lot of creates and updates through ActiveRecord.
&lt;/td&gt;&lt;td&gt;

&lt;b&gt;Rails 1.2&lt;/b&gt;
&lt;pre&gt;&lt;code&gt;
module ActiveRecord
    class Base
    private
        def attributes_with_quotes(include_primary_key = true)
            result = {}
            @attributes.each_key do |name|
                if column = column_for_attribute(name)
                    result[name] = quote_value(read_attribute(name), column) unless !include_primary_key &amp;&amp; column.primary
                end
            end
            result
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;b&gt;Rails 2.0&lt;/b&gt;
&lt;pre&gt;&lt;code&gt;
module ActiveRecord
    class Base
    private
        def attributes_with_quotes(include_primary_key = true, include_readonly_attributes = true)
            quoted = {}
            @attributes.each_pair do |name, value|
                if column = column_for_attribute(name)
                    quoted[name] = quote_value(read_attribute(name), column) unless !include_primary_key &amp;&amp; column.primary
                end
            end
            include_readonly_attributes ? quoted : remove_readonly_attributes(quoted)
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

Rails surrounds every SQL call and &lt;code&gt;ActionView::Base#render&lt;/code&gt; with &lt;code&gt;Benchmark#realtime&lt;/code&gt;. &lt;code&gt;Benchmark#realtime&lt;/code&gt; allocates unnecessary 45k per call.

&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
When copying 120 tasks in Acunote this costs 120M. Patch improves performance from 6s to 5s.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
Helps when you do read, create, update lots of AR records, or execute any other SQL, or call #render(:partial) in a loop.

&lt;/td&gt;&lt;td&gt;

&lt;pre&gt;&lt;code&gt;
module Benchmark
    def realtime
        r0 = Time.now
        yield
        r1 = Time.now
        r1.to_f - r0.to_f
    end
    module_function :realtime
end
&lt;/code&gt;&lt;/pre&gt;

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

Rails 1.2 tries to pretty-print and log every SQL statement even when logger is in Logger::INFO mode (production environment) and prints nothing.

&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
When copying 120 tasks in Acunote this costs 17M. Patch improves performance by 1s.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
Helps when you do read, create, update lots of AR records, or execute any other SQL in a loop.&lt;br/&gt;
Patch only applicable to Rails 1.2. Rails 2.0 has the correct log_info implementation.

&lt;/td&gt;&lt;td&gt;

&lt;b&gt;Rails 1.2&lt;/b&gt;
&lt;pre&gt;&lt;code&gt;
module ActiveRecord
    module ConnectionAdapters
        class AbstractAdapter
        protected
            def log_info_with_level_check(sql, name, runtime)
                return unless @logger and @logger.level == Logger::DEBUG
                log_info_without_level_check(sql, name, runtime)
            end
            alias_method_chain :log_info, :level_check
        end
    end
end
&lt;/pre&gt;&lt;/code&gt;
&lt;b&gt;Rails 2.0&lt;/b&gt;&lt;br/&gt;
No patch necessary.

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

Comparison of BigDecimal's (used by Rails for Numeric data types) to booleans is slow because it requires unnecessary method_missing call and exception catch.

&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
When rendering 120 tasks in Acunote this costs 4M. Patch improves performance by 100-120ms.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
Helps when you have the imprudence to accidentally compare BigDecimal's with true or false.

&lt;/td&gt;&lt;td&gt;

&lt;pre&gt;&lt;code&gt;
class BigDecimal
    alias_method :eq_without_boolean_comparison, :==
    def eq_with_boolean_comparison(other)
        return false if [FalseClass, TrueClass].include? other.class
        eq_without_boolean_comparison(other)
    end
    alias_method :==, :eq_with_boolean_comparison
end
&lt;/pre&gt;&lt;/code&gt;

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

&lt;code&gt;ActionView::Helpers::JavaScriptHelper&lt;wbr/&gt;#link_to_function&lt;/code&gt; allocates lots of memory when run. It runs every time view is rendered.

&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
When rendering 120 tasks in Acunote this costs 5M. This improves performance by 100-110ms.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
Helps when you have rich AJAX page with lots of dynamic elements.
It's worth elimitinating helpers in hostposts identified by memory
profiler. Cumulatively this has huge impact on render-bound requests.

&lt;/td&gt;&lt;td&gt;

Hand-replace &lt;code&gt;link_to_function&lt;/code&gt; with &lt;code&gt;&amp;lt;a href="#" onclick="..."/&amp;gt;&lt;/code&gt;.

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

&lt;code&gt;ActionView::Helpers::FormTagHelper&lt;wbr/&gt;#text_field_tag&lt;/code&gt; allocates lots of memory when run. It runs every time view is rendered.

&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
When rendering 120 tasks in Acunote this costs 2M. This improves performance by 40-50ms.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
Helps when you have page with lots of input boxes.  It's worth elimitinating helpers in hostposts identified by memory profiler. Cumulatively this has huge impact on render-bound requests.

&lt;/td&gt;&lt;td&gt;
Hand-replace &lt;code&gt;text_field_tag&lt;/code&gt; with &lt;code&gt;&amp;lt;input type="text"/&amp;gt;&lt;/code&gt;.

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

&lt;code&gt;ActionView::Helpers::AssetTagHelper&lt;wbr/&gt;#image_tag&lt;/code&gt; allocates lots of memory when run. It runs every time view is rendered.

&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
When rendering 120 tasks in Acunote this costs 8M. This improves performance by 110-150ms.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
Helps when you have page with lots of images. It's worth elimitinating helpers in hostposts identified by memory profiler. Cumulatively this has huge impact on render-bound requests. &lt;code&gt;image_tag&lt;/code&gt; itself can be optimized. Help wanted.

&lt;/td&gt;&lt;td&gt;

If you don't use asset hosts, hand-replace &lt;code&gt;image_tag&lt;/code&gt; with &lt;code&gt;&amp;lt;img src="..."/&amp;gt;&lt;/code&gt;.&lt;br/&gt;
If you use asset hosts, there's no patch.

&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;

Passing a block to a method on instance of &lt;code&gt;ActiveRecord::Associations&lt;wbr&gt;::{HasAndBelongsToManyAssociation /etc.}&lt;/code&gt; chews up memory.&lt;br/&gt;
An example (from activerecord/lib&lt;wbr/&gt;/activerecord/associations.rb) is &lt;code&gt;association.select { |record| record.new_record? }&lt;/code&gt; line inside &lt;code&gt;#add_multiple_associated&lt;wbr/&gt;_save_callbacks&lt;/code&gt; method.

&lt;br/&gt;
&lt;br/&gt;
&lt;b&gt;Impact:&lt;/b&gt;&lt;br/&gt;
This is used all over ActiveRecord code, and often by application code.
&lt;br/&gt;&lt;b&gt;Notes:&lt;/b&gt;&lt;br/&gt;
We have been unable to figure out the root cause. Help wanted. Separate article to come.

&lt;/td&gt;&lt;td&gt;

None known.&lt;br/&gt;
Sometimes it helps to convert association to array before using, for example &lt;code&gt;association.to_a.select { |record| record.new_record? }&lt;/code&gt;

&lt;/td&gt;&lt;tr&gt;&lt;/table&gt;

&lt;h2&gt;How can I help?&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Profile memory allocations for your Rails application.  Figure out
and fix hotspots.  &lt;strong&gt;Post or link to patches and notes in the
comments&lt;/strong&gt; section.  We'll be updating this post, as you and we
figure out more.&lt;/li&gt;
&lt;li&gt;If you are writing a large commercial Rails application, have one of
you engineers do some memory profiling.  Fast is a feature, and it's
a nice way to contribute to the community.&lt;/li&gt;
&lt;li&gt;Help us figure out the some of the issues we found, but haven't been
able to figure out yet.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Submitted Patches&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blade.nagaokaut.ac.jp/cgi-bin/scat.rb/ruby/ruby-core/15337"&gt;&lt;code&gt;Benchmark#realtime&lt;/code&gt; patch&lt;/a&gt;&lt;br/&gt;Patch accepted. Matz committed it to Ruby 1.8 branch.  Also, &lt;a href="http://dev.rubyonrails.org/changeset/8771"&gt;included&lt;/a&gt; in Rails trunk.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.rubyonrails.org/ticket/10978"&gt;&lt;code&gt;ActiveRecord::Base#attributes_with_quotes&lt;/code&gt; patch&lt;/a&gt;&lt;br/&gt;Patch accepted. Michael Koziarski &lt;a href="http://dev.rubyonrails.org/changeset/8770"&gt;committed&lt;/a&gt; it to Rails trunk.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Thanks To&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Alexander Dymo for actually doing all the work&lt;/li&gt;
&lt;li&gt;Alexander Goldstein for directing us to look at GC in the first place&lt;/li&gt;
&lt;li&gt;DHH and rails-core for giving us something to optimize, and for
making Rails code so easy to understand and modify&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cfis.savagexi.com"&gt;Charlie Savage&lt;/a&gt; and &lt;a href="http://blog.shugo.net/"&gt;Shugo
Maeda&lt;/a&gt; for &lt;a href="http://ruby-prof.rubyforge.org/"&gt;ruby-prof&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sylvain Joyeux's for original memory allocations number measurement
patch&lt;/li&gt;
&lt;li&gt;&lt;a href="http://railsexpress.de/blog/"&gt;Stefan Kaes&lt;/a&gt; for all his performance
work, &lt;a href="http://railsbench.rubyforge.org/"&gt;railsbench&lt;/a&gt; and especially
&lt;a href="http://railsbench.rubyforge.org/svn/trunk/railsbench/GCPATCH"&gt;GC patch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Sightings&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Charlie Savage: &lt;a href="http://cfis.savagexi.com/articles/2008/02/02/must-read-rails-performance-article"&gt;Must Read Rails Performance
Article&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Charlie Savage: &lt;a href="http://cfis.savagexi.com/articles/2008/02/03/ruby-prof-0-6-0-and-memory-profiling"&gt;ruby-prof 0.6.0 and Memory
Profiling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ruby Inside: &lt;a href="http://www.rubyinside.com/interesting-ruby-tidbits-that-dont-need-separate-posts-15-710.html"&gt;Fixing Ruby &amp;amp; Rails' slow performance with
patches!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Michael Klishin: &lt;a href="http://www.novemberain.com/2008/2/2/call-for-action-do-you-wanna-5-times-faster-rails-applications"&gt;Making Ruby on Rails applications 5 times
faster: patches
attached&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wes Maldonado: &lt;a href="http://www.brokenbuild.com/blog/2008/02/01/acunotenimble-method-patches-speeding-up-ruby-on-rails/"&gt;Acunote/Nimble Method Patches Speeding up Ruby on
Rails&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Accelerate HR: &lt;a href="http://jobwd.com/article/show/32"&gt;More notes on super-fast data insertion in
Rails&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Chu Yeow &lt;a href="http://blog.codefront.net/2008/02/06/living-on-the-edge-of-rails-6-better-performance-git-support-and-more/"&gt;Living on the edge (of Rails) #6 - better performance,
Git support, and
more&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Antares Trader: &lt;a href="http://blog.antarestrader.com/?p=31"&gt;Collecting the Garbage in
Ruby&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;edhickey.com: &lt;a href="http://blog.edhickey.com/2008/02/08/mongrel-memory-usage/"&gt;Mongrel memory
usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Mike Perham: &lt;a href="http://www.mikeperham.com/2008/02/06/tuning-activerecord"&gt;Tuning ActiveRecord&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Updates&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Update 1: noted that patches are against 1.2.4  Requested patches against 2.0&lt;/li&gt;
&lt;li&gt;Update 2: added patches against Rails 2.0&lt;/li&gt;
&lt;li&gt;Update 3: added "submitted patches" section with upstream patches&lt;/li&gt;
&lt;li&gt;Update 4: #realtime and #attributes_with_quotes patches accepted upstream&lt;/li&gt;
&lt;li&gt;Update 5: added Sightings section&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;img src="http://feeds.feedburner.com/~r/pluron/~4/226896883" height="1" width="1"/&gt;</content>


    <feedburner:origLink>http://blog.pluron.com/2008/01/ruby-on-rails-i.html</feedburner:origLink></entry>
 
</feed>
